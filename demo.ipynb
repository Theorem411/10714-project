{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugqA0Huhx6NY"
   },
   "source": [
    "# Integrating needle with TVM\n",
    "\n",
    "This is a demo for our Deep Learning System (10714) course's final project. Our project extends our needle framework with the ability to generate TVMScript, which open the door to many powerful machine learning model optimizations.\n",
    "\n",
    "## Introduction to TVM\n",
    "\n",
    "TVM is an open-source machine learning compiler stack designed to optimize and deploy deep learning models across various hardware platforms. It provides a unified framework for transforming high-level model descriptions into optimized tensor programs that can run efficiently on CPUs, GPUs, and specialized accelerators like TPUs. By integrating TVM into Needle, we unlock several powerful optimization techniques that dramatically improve model performance, including Graph-Level Optimizations, Tensor Program-Level Optimizations, and Cross-Hardware Compatibility. In the following sections, we will delve deeper into each step of the integration process.\n",
    "\n",
    "We will conduct performance experiment on the following models to demonstrate the power of TVM optimizations:\n",
    "\n",
    "-   MLP: A simple feed-forward model that serves as a baseline for optimization comparison.\n",
    "-   Resnet9: A convolutional neural network model often used for image classification tasks.\n",
    "-   Transformer: A model designed for sequence-to-sequence tasks, such as machine translation or text summarization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7c8llRM62MJC"
   },
   "source": [
    "## Approach Overview:\n",
    "\n",
    "### Graph Transpiler: from `ndl.Tensor` to `relax.IRModule`\n",
    "\n",
    "Our translation logic can be founded in `./dlsys/python/needle_tvm/to_tvm.py`.\n",
    "\n",
    "Our main task is to build a graph transpiler that converts needle's computation graph to TVM's `IRModule`. We took advantage of `ndl.Tensor`'s inherent graphical structure to design our translation algorithm. Once a needle model's forward pass is run, we will be able to traverse the tensor graph through a simple topological sort, starting from the output Tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQ3eV6lp7EDj"
   },
   "outputs": [],
   "source": [
    "def topological_sort(output):\n",
    "  visited = set()\n",
    "  topo_order = []\n",
    "\n",
    "  def dfs(node):\n",
    "      if node in visited:\n",
    "          return\n",
    "      visited.add(node)\n",
    "      for inp in node.inputs:\n",
    "          dfs(inp)\n",
    "      topo_order.append(node)\n",
    "\n",
    "  dfs(output)\n",
    "  return topo_order  # Reverse for topological order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8uijzMw-p_j"
   },
   "source": [
    "While we traverse the tensor graph, we incrementally build the final `tvm.IRModule` through `tvm.relax.block_builder` API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YAz7Qoti-p_j"
   },
   "outputs": [],
   "source": [
    "def to_tvm_tensor(mod: ndl.nn.Module, *args, **kwargs) -> tvm.relax.IRModule:\n",
    "  # set user input Tensor placeholder=True\n",
    "  for t in args:\n",
    "    if isinstance(t, Tensor):\n",
    "      t.placeholder = True\n",
    "\n",
    "  # topologically sort ndl.Tensor computation graph\n",
    "  topo_order = topological_sort(output_tensor)\n",
    "\n",
    "  # initialize block builder, module inputs/outputs, value to relax.Var map\n",
    "  bb = block_builder.BlockBuilder()\n",
    "  fn_inputs = []\n",
    "  fn_output = None\n",
    "  value_to_var : Dict[ndl.Tensor, relax.Var] = {}\n",
    "\n",
    "\n",
    "  # Create the \"main\" function in emitted IRModule\n",
    "  with bb.function(\"main\"):\n",
    "      with bb.dataflow():\n",
    "          for i, node in enumerate(topo_order):\n",
    "              # Leaf nodes (inputs or constants)\n",
    "              if node.is_leaf():\n",
    "                  if node.placeholder:\n",
    "                      tvm_var = (relax.Var(\"X\", relax.TensorStructInfo(node.shape, \"float32\")))\n",
    "                      value_to_var.setdefault(node, tvm_var)\n",
    "                      fn_inputs.append(tvm_var)\n",
    "                      continue\n",
    "                  else:\n",
    "                      tvm_var = (relax.const(node.numpy(), relax.TensorStructInfo(node.shape, \"float32\")))\n",
    "                      value_to_var.setdefault(node, tvm_var)\n",
    "                      continue\n",
    "\n",
    "              # Map the operation to TVM\n",
    "              tvm_var = node.op.emit_te(bb, value_to_var, node)\n",
    "              value_to_var[node] = tvm_var\n",
    "\n",
    "          fn_output = bb.emit_output(value_to_var[topo_order[-1]])\n",
    "\n",
    "      bb.emit_func_output(value_to_var[topo_order[-1]], fn_inputs)\n",
    "  return bb.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmjQxFol-p_j"
   },
   "source": [
    "We uses a dictionary that maps `ndl.Tensor` to `relax.Var` to query intermediate translation results. A `relax.Var` represents the result of a computation in `IRModule`. It could be one of three things:\n",
    "\n",
    "1. A placeholder, i.e. model inputs\n",
    "2. A constant, e.g. model parameters\n",
    "3. Result of a tensor operator\n",
    "\n",
    "Not so coincidentally, needle `Tensor` can also be classified into these three categories. The input `Tensor` to user's model will be \"placeholder\" to the `main` TIR function; model weights and biases will be constant (`relax.const`); and since any non-leaf `Tensor` are coupled with a `TensorOp` (the `Tensor.op`), we can translate the operator as a Tensor IR function, and insert a call instruction to said function in the `main` TIR function of the final `IRModule`.\n",
    "\n",
    "For the first kind, we add an boolean attribute `placeholder` to `Value` class (parent of `Tensor`) to indicate if a `Tensor` is an input to user's model. Once detected, our translation algorithm will correspondingly generate a `relax.Var`. This also explains why our `to_tvm_tensor` function does this in the beginning:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mc8qOPP3-p_k"
   },
   "outputs": [],
   "source": [
    "# set user input Tensor placeholder=True\n",
    "for t in args:\n",
    "  if isinstance(t, Tensor):\n",
    "    t.placeholder = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ofGxQKUB-p_k"
   },
   "source": [
    "For the last kind of `Tensor`, we generate the corresponding `TensorIR` function in the `IRModule` using `tvm.topi` operators. In `./dlsys/python/needle/ops/ops_mathematics.py`, we extend every `TensorOp` with a `emit_te` function, e.g. in `EwiseAdd.emit_te`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omjYgaGB-p_k"
   },
   "outputs": [],
   "source": [
    "class EWiseAdd(TensorOp):\n",
    "    def emit_te(self, bb: relax.BlockBuilder, node_map: Dict[Tensor, relax.Var], node: Tensor) -> relax.Var:\n",
    "        A = node_map[node.inputs[0]]\n",
    "        B = node_map[node.inputs[1]]\n",
    "\n",
    "        def te_ewise_add(A, B):\n",
    "            return topi.add(A, B)\n",
    "\n",
    "        return bb.emit_te(te_ewise_add, A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLIR2gAA-p_l"
   },
   "source": [
    "`relax.BlockBuilder.emit_te` will generate the following TIR function in the final `IRModule`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXTkOG7H-p_l"
   },
   "outputs": [],
   "source": [
    "@T.prim_func(private=True)\n",
    "def te_ewise_add(lv: T.Buffer((T.int64(32), T.int64(512)), \"float32\"), lv2: T.Buffer((T.int64(32), T.int64(512)), \"float32\"), T_add: T.Buffer((T.int64(32), T.int64(512)), \"float32\")):\n",
    "    T.func_attr({\"tir.noalias\": T.bool(True)})\n",
    "    # with T.block(\"root\"):\n",
    "    for ax0, ax1 in T.grid(T.int64(32), T.int64(512)):\n",
    "        with T.block(\"T_add\"):\n",
    "            v_ax0, v_ax1 = T.axis.remap(\"SS\", [ax0, ax1])\n",
    "            T.reads(lv[v_ax0, v_ax1], lv2[v_ax0, v_ax1])\n",
    "            T.writes(T_add[v_ax0, v_ax1])\n",
    "            T_add[v_ax0, v_ax1] = lv[v_ax0, v_ax1] + lv2[v_ax0, v_ax1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLbM0G1T-p_l"
   },
   "source": [
    "### Build and Save `IRModule` as Executable\n",
    "\n",
    "Our model compile and evaluation logic can be found in `./dlsys/apps/models/model_eval.py` in class `ModelEval`.\n",
    "\n",
    "The following code builds and runs the `IRModule` transpiled from our `ndl.nn.Module` using TVM `Relax` frontend:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_Ouao6j-p_l"
   },
   "source": [
    "**_Note_**:\n",
    "For `nn.Module` that uses have different behavior during inference and training (e.g. `BatchNorm1d`), it's absolutely necessary to run `model.eval()` before calling `to_tvm_tensor` to ensure the transpiled tvm module is indeed from model's inference path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2I8DXx2-p_l"
   },
   "outputs": [],
   "source": [
    "# ensure model is inference mode\n",
    "model.eval()\n",
    "\n",
    "ir_module = to_tvm_tensor(model, ndl.Tensor(x, device=self.ndl_device))\n",
    "module_ex = relax.build(ir_module, target=\"llvm\")\n",
    "module_vm = relax.VirtualMachine(module_ex, self.tvm_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58dsdgnG-p_l"
   },
   "source": [
    "while the following code saves the executable as a shared library (`.so`) to be reloaded. For our project we save model executables in `./dlsys/apps/models/module_lib/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3y3fxpHG-p_l"
   },
   "outputs": [],
   "source": [
    "module_ex.export_library(module_save_path)\n",
    "...\n",
    "module_ex = tvm.runtime.load_module(module_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWjU0NvD-p_l"
   },
   "source": [
    "Finally, we run the compiled TVM module. We check correctness by running needle model side-by-side and compare final activation layer values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYuYeyEB-p_l"
   },
   "outputs": [],
   "source": [
    "input_ndl = ndl.Tensor(X, device=self.ndl_device, requires_grad=False, placeholder=True)\n",
    "input_tvm = tvm.nd.array(X)\n",
    "\n",
    "ndl_out = self.model(input_ndl)\n",
    "tvm_out = self.module_vm[\"main\"](input_tvm)\n",
    "\n",
    "try:\n",
    "  assert np.allclose(tvm_out.asnumpy(),ndl_out.numpy(), atol=1e-4) # tweak tolerance if fails\n",
    "except AssertionError:\n",
    "  # Compute the absolute difference between two outputs\n",
    "  abs_diff = np.abs(np.linalg.norm(tvm_out.asnumpy()) - np.linalg.norm(ndl_out.numpy()))\n",
    "  print(f\"TVM-NDL diff norm: {abs_diff}\")\n",
    "  raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9u4aCA9C-p_m"
   },
   "source": [
    "### Tensor Program and Computational Graph Optimization\n",
    "\n",
    "TVM provides ways to optimize `IRModule` at two level:\n",
    "\n",
    "-   Tensor program level: loop parallelization, tiling, vectorization, etc.\n",
    "-   Computational graph level: operator fusion, layout transformation, memory management.\n",
    "\n",
    "We perform operator fusion on the transpiled `IRModule`. Below is our optimization pipeline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tK9rhu1Z-p_m"
   },
   "outputs": [],
   "source": [
    "# ir_module derived from to_tvm_tensor\n",
    "ir_module = tvm.ir.transform.Sequential([\n",
    "  tvm.relax.transform.LegalizeOps(),\n",
    "  tvm.relax.transform.AnnotateTIROpPattern(),\n",
    "  tvm.relax.transform.FuseOps(),\n",
    "  tvm.relax.transform.FuseTIR(),\n",
    "])(ir_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MhK370c-p_m"
   },
   "source": [
    "As for tensor program optimizations, we utilize TVM's `meta_schedule` feature to automatically discover optimizations within each TIR function. It enables workload tuning through either custom-defined search spaces or the system's built-in, automatically generated search spaces. In this project, we utilize the autotuning capabilities of meta_schedule to explore and maximize potential performance gains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2kWpJZW-p_m"
   },
   "outputs": [],
   "source": [
    "# detect number of cores for loop parallelization\n",
    "target = \"llvm\" + f\" -num-cores={os.cpu_count()}\"\n",
    "\n",
    "# Iterate over all functions in the IRModule\n",
    "funcs = 0\n",
    "for func_name in ir_module.get_global_vars():\n",
    "    funcs += 1\n",
    "    if max_funcs is not None and funcs > max_funcs: break\n",
    "    try:\n",
    "        func_name_str = func_name.name_hint\n",
    "        print(f\"tuning: {func_name_str}\")\n",
    "        # Create a tuning database for each function\n",
    "        mod_func = tvm.IRModule.from_expr(ir_module[func_name].with_attr(\"global_symbol\", func_name_str))\n",
    "\n",
    "        # Tune the TIR function\n",
    "        database = meta_schedule.tune_tir(\n",
    "            mod=mod_func,                 # Input module\n",
    "            target=target,                # Target platform (e.g., \"llvm\", \"cuda\")\n",
    "            max_trials_global=5,          # Total tuning trials\n",
    "            num_trials_per_iter=5,        # Trials per tuning iteration\n",
    "            work_dir=f\"{work_dir}/{func_name_str}\",  # Separate logs for each function\n",
    "        )\n",
    "\n",
    "        # Compile the tuned TIR function into a new IRModule\n",
    "        sch = meta_schedule.tir_integration.compile_tir(\n",
    "            database=database,           # The tuning database\n",
    "            mod=mod_func,                # Input module to compile\n",
    "            target=target                # Target platform\n",
    "        )\n",
    "\n",
    "        # Update the module with the tuned function\n",
    "        updated_mod = sch.mod[\"main\"].with_attr(\"global_symbol\", func_name_str)\n",
    "        gv = ir_module.get_global_var(func_name_str)\n",
    "        ir_module.update_func(gv, updated_mod)\n",
    "\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUmATAqN-p_m"
   },
   "source": [
    "Although compute-intensive, `meta_schedule` excels at uncovering a wide range of optimizations beyond just tiling. What impressed us most was its remarkable generalizability in identifying optimizations for loop nests of varying shapes and sizes. Unsurprisingly, the optimized IRModule significantly outperforms our needle model, which uses register-tiling exclusively for matrix multiplication kernels.\n",
    "\n",
    "Below is an example of the effects of `meta_schedule` on `reshape`'s TIR function. We were able to see `meta_schedule` discovers loop parallelization, vectorization, and tiling within the loop nest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0XZrLxBf-p_m"
   },
   "outputs": [],
   "source": [
    "@T.prim_func\n",
    "def te_reshape(A: T.Buffer((T.int64(1), T.int64(2048)), \"float32\"), T_reshape: T.Buffer((T.int64(3), T.int64(2048)), \"float32\")):\n",
    "T.func_attr({\"op_pattern\": 2, \"tir.noalias\": T.bool(True)})\n",
    "# with T.block(\"root\"):\n",
    "for ax0_ax1_fused_0 in T.parallel(T.int64(32)):\n",
    "  for ax0_ax1_fused_1 in T.vectorized(T. int64(64)):\n",
    "    with T.block(\"T_reshape\"):\n",
    "      v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))\n",
    "      v_ax1 = T.axis.spatial(T.int64(2048), ax0_ax1_fused_0 * T.int64(64) + ax0_ax1_tused_1)\n",
    "      T.reads(A[T.int64(0), v_ax1 % T.Int64(2948)])\n",
    "      T.writes(T_reshape[v_ax0, v_ax1])\n",
    "      T_reshape[vax0, v_ax1] = A[T.int64(0), v_ax1 % T. Int64(2048)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GRmXu94w2IT_"
   },
   "source": [
    "# Code Demo: CPU Device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1733774726298,
     "user": {
      "displayName": "Vedant Bhasin",
      "userId": "16901580205563811674"
     },
     "user_tz": 300
    },
    "id": "e3H-DFsd0s60",
    "outputId": "b1f6a654-96aa-4b93-8536-adb08f628f3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/10714/10714-project\n",
      "make: *** No targets specified and no makefile found.  Stop.\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/\n",
    "!mkdir -p 10714\n",
    "%cd 10714\n",
    "!git clone https://github.com/Theorem411/10714-project\n",
    "%cd /content/drive/MyDrive/10714/10714-project/\n",
    "\n",
    "!pip3 install pybind11\n",
    "# Install tvm\n",
    "!python -m pip install --pre -U -f https://mlc.ai/wheels mlc-ai-nightly-cu122\n",
    "!python -c \"from tvm import relax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35544,
     "status": "ok",
     "timestamp": 1733774834620,
     "user": {
      "displayName": "Vedant Bhasin",
      "userId": "16901580205563811674"
     },
     "user_tz": 300
    },
    "id": "akSK_JzA-p_m",
    "outputId": "2b680d98-213b-4e3e-f735-bc4d36fdcd67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONPATH=./dlsys/python\n",
      "env: NEEDLE_BACKEND=nd\n",
      "/content/drive/MyDrive/10714/10714-project/dlsys\n",
      "rm -rf build python/needle/backend_ndarray/ndarray_backend*.so\n",
      "-- The C compiler identification is GNU 11.4.0\n",
      "-- The CXX compiler identification is GNU 11.4.0\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Check for working C compiler: /usr/bin/cc - skipped\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Found Python: /usr/local/bin/python (found version \"3.10.12\") found components: Development Interpreter Development.Module Development.Embed\n",
      "-- Performing Test HAS_FLTO\n",
      "-- Performing Test HAS_FLTO - Success\n",
      "-- Found pybind11: /usr/local/lib/python3.10/dist-packages/pybind11/include (found version \"2.13.6\")\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
      "-- Found Threads: TRUE\n",
      "-- Found CUDA: /usr/local/cuda (found version \"12.2\")\n",
      "-- Found cuda, building cuda backend\n",
      "Mon Dec  9 20:06:43 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   44C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "-- Autodetected CUDA architecture(s):  7.5\n",
      "-- Configuring done (5.3s)\n",
      "-- Generating done (0.3s)\n",
      "-- Build files have been written to: /content/drive/MyDrive/10714/10714-project/dlsys/build\n",
      "make[1]: Entering directory '/content/drive/MyDrive/10714/10714-project/dlsys/build'\n",
      "make[2]: Entering directory '/content/drive/MyDrive/10714/10714-project/dlsys/build'\n",
      "make[3]: Entering directory '/content/drive/MyDrive/10714/10714-project/dlsys/build'\n",
      "make[3]: Leaving directory '/content/drive/MyDrive/10714/10714-project/dlsys/build'\n",
      "make[3]: Entering directory '/content/drive/MyDrive/10714/10714-project/dlsys/build'\n",
      "[-25%] \u001b[32mBuilding CXX object CMakeFiles/ndarray_backend_cpu.dir/src/ndarray_backend_cpu.cc.o\u001b[0m\n",
      "[  0%] \u001b[32m\u001b[1mLinking CXX shared module /content/drive/MyDrive/10714/10714-project/dlsys/python/needle/backend_ndarray/ndarray_backend_cpu.cpython-310-x86_64-linux-gnu.so\u001b[0m\n",
      "make[3]: Leaving directory '/content/drive/MyDrive/10714/10714-project/dlsys/build'\n",
      "[  0%] Built target ndarray_backend_cpu\n",
      "make[3]: Entering directory '/content/drive/MyDrive/10714/10714-project/dlsys/build'\n",
      "[ 25%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/ndarray_backend_cuda.dir/src/ndarray_backend_cuda_generated_ndarray_backend_cuda.cu.o\u001b[0m\n",
      "/content/drive/MyDrive/10714/10714-project/dlsys/src/ndarray_backend_cuda.cu(408): warning #177-D: variable \"m_tiles\" was declared but never referenced\n",
      "    uint32_t m_tiles = (M + 4 - 1 / 4);\n",
      "             ^\n",
      "\n",
      "Remark: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
      "\n",
      "/content/drive/MyDrive/10714/10714-project/dlsys/src/ndarray_backend_cuda.cu(410): warning #177-D: variable \"p_tiles\" was declared but never referenced\n",
      "    uint32_t p_tiles = (P + 4 - 1 / 4);\n",
      "             ^\n",
      "\n",
      "/content/drive/MyDrive/10714/10714-project/dlsys/src/ndarray_backend_cuda.cu(412): warning #177-D: variable \"i\" was declared but never referenced\n",
      "    uint32_t i = blockIdx.x * blockDim.x;\n",
      "             ^\n",
      "\n",
      "/content/drive/MyDrive/10714/10714-project/dlsys/src/ndarray_backend_cuda.cu(413): warning #177-D: variable \"j\" was declared but never referenced\n",
      "    uint32_t j = blockIdx.y * blockDim.y;\n",
      "             ^\n",
      "\n",
      "make[3]: Leaving directory '/content/drive/MyDrive/10714/10714-project/dlsys/build'\n",
      "make[3]: Entering directory '/content/drive/MyDrive/10714/10714-project/dlsys/build'\n",
      "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module /content/drive/MyDrive/10714/10714-project/dlsys/python/needle/backend_ndarray/ndarray_backend_cuda.cpython-310-x86_64-linux-gnu.so\u001b[0m\n",
      "make[3]: Leaving directory '/content/drive/MyDrive/10714/10714-project/dlsys/build'\n",
      "[ 50%] Built target ndarray_backend_cuda\n",
      "make[2]: Leaving directory '/content/drive/MyDrive/10714/10714-project/dlsys/build'\n",
      "make[1]: Leaving directory '/content/drive/MyDrive/10714/10714-project/dlsys/build'\n"
     ]
    }
   ],
   "source": [
    "%set_env PYTHONPATH ./dlsys/python\n",
    "%set_env NEEDLE_BACKEND nd\n",
    "%set_env APP_DIR /content/drive/MyDrive/10714/10714-project/dlsys/apps/\n",
    "\n",
    "%cd /content/drive/MyDrive/10714/10714-project/dlsys\n",
    "!make clean && make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsSvnl3f-p_n"
   },
   "source": [
    "### MLP Performance\n",
    "\n",
    "**_Note:_** meta scheduling for `Transformer` and `ResNet9` model might take rounghly **_10-15 minutes_** to finish on the first run. However, since we reload the compiled module executable, the second time would be significantly faster as we bypass the meta scheduler.\n",
    "\n",
    "If you want to recompile the model, add `-r` flag when running `tvm_eval.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75197,
     "status": "ok",
     "timestamp": 1733774934087,
     "user": {
      "displayName": "Vedant Bhasin",
      "userId": "16901580205563811674"
     },
     "user_tz": 300
    },
    "id": "VLyPjsrE-p_n",
    "outputId": "f1022bf9-df38-40dc-a33d-b8effdbb4d9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/10714/10714-project/dlsys/apps\n",
      "Using needle backend\n",
      "===== original module=====\n",
      "\u001b[90;03m# from tvm.script import ir as I\u001b[39;00m\n",
      "\u001b[90;03m# from tvm.script import tir as T\u001b[39;00m\n",
      "\u001b[90;03m# from tvm.script import relax as R\u001b[39;00m\n",
      "\n",
      "\u001b[95;03m@I\u001b[39;00m\u001b[35;01m.\u001b[39;00mir_module\n",
      "\u001b[32;01mclass\u001b[39;00m \u001b[34;01mModule\u001b[39;00m:\n",
      "    \u001b[95;03m@T\u001b[39;00m\u001b[35;01m.\u001b[39;00mprim_func(private\u001b[35;01m=\u001b[39;00m\u001b[32;01mTrue\u001b[39;00m)\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mte_broadcast_to\u001b[39;00m(lv1: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), T_broadcast_to: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "        T\u001b[35;01m.\u001b[39;00mfunc_attr({\u001b[33m\"\u001b[39m\u001b[33mtir.noalias\u001b[39m\u001b[33m\"\u001b[39m: T\u001b[35;01m.\u001b[39;00mbool(\u001b[32;01mTrue\u001b[39;00m)})\n",
      "        \u001b[90;03m# with T.block(\"root\"):\u001b[39;00m\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0, ax1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)):\n",
      "            \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_broadcast_to\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                v_ax0, v_ax1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mremap(\u001b[33m\"\u001b[39m\u001b[33mSS\u001b[39m\u001b[33m\"\u001b[39m, [ax0, ax1])\n",
      "                T\u001b[35;01m.\u001b[39;00mreads(lv1[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v_ax1])\n",
      "                T\u001b[35;01m.\u001b[39;00mwrites(T_broadcast_to[v_ax0, v_ax1])\n",
      "                T_broadcast_to[v_ax0, v_ax1] \u001b[35;01m=\u001b[39;00m lv1[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v_ax1]\n",
      "\n",
      "    \u001b[95;03m@T\u001b[39;00m\u001b[35;01m.\u001b[39;00mprim_func(private\u001b[35;01m=\u001b[39;00m\u001b[32;01mTrue\u001b[39;00m)\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mte_ewise_add\u001b[39;00m(lv: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), lv2: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), T_add: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "        T\u001b[35;01m.\u001b[39;00mfunc_attr({\u001b[33m\"\u001b[39m\u001b[33mtir.noalias\u001b[39m\u001b[33m\"\u001b[39m: T\u001b[35;01m.\u001b[39;00mbool(\u001b[32;01mTrue\u001b[39;00m)})\n",
      "        \u001b[90;03m# with T.block(\"root\"):\u001b[39;00m\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0, ax1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)):\n",
      "            \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_add\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                v_ax0, v_ax1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mremap(\u001b[33m\"\u001b[39m\u001b[33mSS\u001b[39m\u001b[33m\"\u001b[39m, [ax0, ax1])\n",
      "                T\u001b[35;01m.\u001b[39;00mreads(lv[v_ax0, v_ax1], lv2[v_ax0, v_ax1])\n",
      "                T\u001b[35;01m.\u001b[39;00mwrites(T_add[v_ax0, v_ax1])\n",
      "                T_add[v_ax0, v_ax1] \u001b[35;01m=\u001b[39;00m lv[v_ax0, v_ax1] \u001b[35;01m+\u001b[39;00m lv2[v_ax0, v_ax1]\n",
      "\n",
      "    \u001b[95;03m@T\u001b[39;00m\u001b[35;01m.\u001b[39;00mprim_func(private\u001b[35;01m=\u001b[39;00m\u001b[32;01mTrue\u001b[39;00m)\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mte_matmul\u001b[39;00m(X: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), B: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), T_matmul: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "        T\u001b[35;01m.\u001b[39;00mfunc_attr({\u001b[33m\"\u001b[39m\u001b[33mtir.noalias\u001b[39m\u001b[33m\"\u001b[39m: T\u001b[35;01m.\u001b[39;00mbool(\u001b[32;01mTrue\u001b[39;00m)})\n",
      "        \u001b[90;03m# with T.block(\"root\"):\u001b[39;00m\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0, ax1, k \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)):\n",
      "            \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_matmul\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                v_ax0, v_ax1, v_k \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mremap(\u001b[33m\"\u001b[39m\u001b[33mSSR\u001b[39m\u001b[33m\"\u001b[39m, [ax0, ax1, k])\n",
      "                T\u001b[35;01m.\u001b[39;00mreads(X[v_ax0, v_k], B[v_k, v_ax1])\n",
      "                T\u001b[35;01m.\u001b[39;00mwrites(T_matmul[v_ax0, v_ax1])\n",
      "                \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00minit():\n",
      "                    T_matmul[v_ax0, v_ax1] \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00mfloat32(\u001b[92m0.0\u001b[39m)\n",
      "                T_matmul[v_ax0, v_ax1] \u001b[35;01m=\u001b[39;00m T_matmul[v_ax0, v_ax1] \u001b[35;01m+\u001b[39;00m X[v_ax0, v_k] \u001b[35;01m*\u001b[39;00m B[v_k, v_ax1]\n",
      "\n",
      "    \u001b[95;03m@T\u001b[39;00m\u001b[35;01m.\u001b[39;00mprim_func(private\u001b[35;01m=\u001b[39;00m\u001b[32;01mTrue\u001b[39;00m)\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mte_relu\u001b[39;00m(lv3: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), compute: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "        T\u001b[35;01m.\u001b[39;00mfunc_attr({\u001b[33m\"\u001b[39m\u001b[33mtir.noalias\u001b[39m\u001b[33m\"\u001b[39m: T\u001b[35;01m.\u001b[39;00mbool(\u001b[32;01mTrue\u001b[39;00m)})\n",
      "        \u001b[90;03m# with T.block(\"root\"):\u001b[39;00m\n",
      "        \u001b[32;01mfor\u001b[39;00m i0, i1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)):\n",
      "            \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mcompute\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                v_i0, v_i1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mremap(\u001b[33m\"\u001b[39m\u001b[33mSS\u001b[39m\u001b[33m\"\u001b[39m, [i0, i1])\n",
      "                T\u001b[35;01m.\u001b[39;00mreads(lv3[v_i0, v_i1])\n",
      "                T\u001b[35;01m.\u001b[39;00mwrites(compute[v_i0, v_i1])\n",
      "                compute[v_i0, v_i1] \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00mmax(lv3[v_i0, v_i1], T\u001b[35;01m.\u001b[39;00mfloat32(\u001b[92m0.0\u001b[39m))\n",
      "\n",
      "    \u001b[95;03m@T\u001b[39;00m\u001b[35;01m.\u001b[39;00mprim_func(private\u001b[35;01m=\u001b[39;00m\u001b[32;01mTrue\u001b[39;00m)\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mte_reshape\u001b[39;00m(A: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), T_reshape: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "        T\u001b[35;01m.\u001b[39;00mfunc_attr({\u001b[33m\"\u001b[39m\u001b[33mtir.noalias\u001b[39m\u001b[33m\"\u001b[39m: T\u001b[35;01m.\u001b[39;00mbool(\u001b[32;01mTrue\u001b[39;00m)})\n",
      "        \u001b[90;03m# with T.block(\"root\"):\u001b[39;00m\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0, ax1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)):\n",
      "            \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_reshape\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                v_ax0, v_ax1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mremap(\u001b[33m\"\u001b[39m\u001b[33mSS\u001b[39m\u001b[33m\"\u001b[39m, [ax0, ax1])\n",
      "                T\u001b[35;01m.\u001b[39;00mreads(A[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v_ax1 \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)])\n",
      "                T\u001b[35;01m.\u001b[39;00mwrites(T_reshape[v_ax0, v_ax1])\n",
      "                T_reshape[v_ax0, v_ax1] \u001b[35;01m=\u001b[39;00m A[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v_ax1 \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)]\n",
      "\n",
      "    \u001b[95;03m@R\u001b[39;00m\u001b[35;01m.\u001b[39;00mfunction\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mmain\u001b[39;00m(X: R\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)) \u001b[35;01m-\u001b[39;00m\u001b[35;01m>\u001b[39;00m R\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "        cls \u001b[35;01m=\u001b[39;00m Module\n",
      "        \u001b[32;01mwith\u001b[39;00m R\u001b[35;01m.\u001b[39;00mdataflow():\n",
      "            lv \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (X, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m0\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv1 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m1\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv2 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_broadcast_to, (lv1,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv3 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_ewise_add, (lv, lv2), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv4 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_relu, (lv3,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv5 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (lv4, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m2\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv6 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m3\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv7 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_broadcast_to, (lv6,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv8 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_ewise_add, (lv5, lv7), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv9 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_relu, (lv8,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv10 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (lv9, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m4\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv11 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m5\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv12 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_broadcast_to, (lv11,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv13 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_ewise_add, (lv10, lv12), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv14 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_relu, (lv13,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv15 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (lv14, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m6\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv16 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m7\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv17 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_broadcast_to, (lv16,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv18 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_ewise_add, (lv15, lv17), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv19 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_relu, (lv18,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv20 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (lv19, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m8\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv21 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m9\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv22 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_broadcast_to, (lv21,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv23 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_ewise_add, (lv20, lv22), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv24 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_relu, (lv23,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            gv: R\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m) \u001b[35;01m=\u001b[39;00m lv24\n",
      "            R\u001b[35;01m.\u001b[39;00moutput(gv)\n",
      "        \u001b[32;01mreturn\u001b[39;00m lv24\n",
      "\n",
      "\u001b[90;03m# Metadata omitted. Use show_meta=True in script() method to show it.\u001b[39;00m\n",
      "\n",
      "noopt module exported to /content/drive/MyDrive/10714/10714-project/dlsys/apps/models/module_lib/mlp-cpu_noopt.so\n",
      "===== transformed module=====\n",
      "\u001b[90;03m# from tvm.script import ir as I\u001b[39;00m\n",
      "\u001b[90;03m# from tvm.script import tir as T\u001b[39;00m\n",
      "\u001b[90;03m# from tvm.script import relax as R\u001b[39;00m\n",
      "\n",
      "\u001b[95;03m@I\u001b[39;00m\u001b[35;01m.\u001b[39;00mir_module\n",
      "\u001b[32;01mclass\u001b[39;00m \u001b[34;01mModule\u001b[39;00m:\n",
      "    \u001b[95;03m@T\u001b[39;00m\u001b[35;01m.\u001b[39;00mprim_func(private\u001b[35;01m=\u001b[39;00m\u001b[32;01mTrue\u001b[39;00m)\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mfused_te_matmul_te_broadcast_to_te_ewise_add_te_relu\u001b[39;00m(X: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), param_0: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), lv1: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), compute_intermediate: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "        T\u001b[35;01m.\u001b[39;00mfunc_attr({\u001b[33m\"\u001b[39m\u001b[33mtir.noalias\u001b[39m\u001b[33m\"\u001b[39m: T\u001b[35;01m.\u001b[39;00mbool(\u001b[32;01mTrue\u001b[39;00m)})\n",
      "        \u001b[90;03m# with T.block(\"root\"):\u001b[39;00m\n",
      "        T_matmul_intermediate \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00malloc_buffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)))\n",
      "        T_broadcast_to_intermediate \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00malloc_buffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)))\n",
      "        T_add_intermediate \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00malloc_buffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)))\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0, ax1, k \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)):\n",
      "            \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_matmul\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                v_ax0, v_ax1, v_k \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mremap(\u001b[33m\"\u001b[39m\u001b[33mSSR\u001b[39m\u001b[33m\"\u001b[39m, [ax0, ax1, k])\n",
      "                T\u001b[35;01m.\u001b[39;00mreads(X[v_ax0, v_k], param_0[v_k, v_ax1])\n",
      "                T\u001b[35;01m.\u001b[39;00mwrites(T_matmul_intermediate[v_ax0, v_ax1])\n",
      "                \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00minit():\n",
      "                    T_matmul_intermediate[v_ax0, v_ax1] \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00mfloat32(\u001b[92m0.0\u001b[39m)\n",
      "                T_matmul_intermediate[v_ax0, v_ax1] \u001b[35;01m=\u001b[39;00m T_matmul_intermediate[v_ax0, v_ax1] \u001b[35;01m+\u001b[39;00m X[v_ax0, v_k] \u001b[35;01m*\u001b[39;00m param_0[v_k, v_ax1]\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0, ax1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)):\n",
      "            \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_broadcast_to\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                v_ax0, v_ax1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mremap(\u001b[33m\"\u001b[39m\u001b[33mSS\u001b[39m\u001b[33m\"\u001b[39m, [ax0, ax1])\n",
      "                T\u001b[35;01m.\u001b[39;00mreads(lv1[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v_ax1])\n",
      "                T\u001b[35;01m.\u001b[39;00mwrites(T_broadcast_to_intermediate[v_ax0, v_ax1])\n",
      "                T_broadcast_to_intermediate[v_ax0, v_ax1] \u001b[35;01m=\u001b[39;00m lv1[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v_ax1]\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0, ax1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)):\n",
      "            \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_add\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                v_ax0, v_ax1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mremap(\u001b[33m\"\u001b[39m\u001b[33mSS\u001b[39m\u001b[33m\"\u001b[39m, [ax0, ax1])\n",
      "                T\u001b[35;01m.\u001b[39;00mreads(T_matmul_intermediate[v_ax0, v_ax1], T_broadcast_to_intermediate[v_ax0, v_ax1])\n",
      "                T\u001b[35;01m.\u001b[39;00mwrites(T_add_intermediate[v_ax0, v_ax1])\n",
      "                T_add_intermediate[v_ax0, v_ax1] \u001b[35;01m=\u001b[39;00m T_matmul_intermediate[v_ax0, v_ax1] \u001b[35;01m+\u001b[39;00m T_broadcast_to_intermediate[v_ax0, v_ax1]\n",
      "        \u001b[32;01mfor\u001b[39;00m i0, i1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)):\n",
      "            \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mcompute\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                v_i0, v_i1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mremap(\u001b[33m\"\u001b[39m\u001b[33mSS\u001b[39m\u001b[33m\"\u001b[39m, [i0, i1])\n",
      "                T\u001b[35;01m.\u001b[39;00mreads(T_add_intermediate[v_i0, v_i1])\n",
      "                T\u001b[35;01m.\u001b[39;00mwrites(compute_intermediate[v_i0, v_i1])\n",
      "                compute_intermediate[v_i0, v_i1] \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00mmax(T_add_intermediate[v_i0, v_i1], T\u001b[35;01m.\u001b[39;00mfloat32(\u001b[92m0.0\u001b[39m))\n",
      "\n",
      "    \u001b[95;03m@T\u001b[39;00m\u001b[35;01m.\u001b[39;00mprim_func(private\u001b[35;01m=\u001b[39;00m\u001b[32;01mTrue\u001b[39;00m)\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mte_reshape\u001b[39;00m(A: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), T_reshape: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "        T\u001b[35;01m.\u001b[39;00mfunc_attr({\u001b[33m\"\u001b[39m\u001b[33mop_pattern\u001b[39m\u001b[33m\"\u001b[39m: \u001b[92m2\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtir.noalias\u001b[39m\u001b[33m\"\u001b[39m: T\u001b[35;01m.\u001b[39;00mbool(\u001b[32;01mTrue\u001b[39;00m)})\n",
      "        \u001b[90;03m# with T.block(\"root\"):\u001b[39;00m\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0, ax1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)):\n",
      "            \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_reshape\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                v_ax0, v_ax1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mremap(\u001b[33m\"\u001b[39m\u001b[33mSS\u001b[39m\u001b[33m\"\u001b[39m, [ax0, ax1])\n",
      "                T\u001b[35;01m.\u001b[39;00mreads(A[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v_ax1 \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)])\n",
      "                T\u001b[35;01m.\u001b[39;00mwrites(T_reshape[v_ax0, v_ax1])\n",
      "                T_reshape[v_ax0, v_ax1] \u001b[35;01m=\u001b[39;00m A[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v_ax1 \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)]\n",
      "\n",
      "    \u001b[95;03m@R\u001b[39;00m\u001b[35;01m.\u001b[39;00mfunction\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mmain\u001b[39;00m(X: R\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)) \u001b[35;01m-\u001b[39;00m\u001b[35;01m>\u001b[39;00m R\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "        cls \u001b[35;01m=\u001b[39;00m Module\n",
      "        \u001b[32;01mwith\u001b[39;00m R\u001b[35;01m.\u001b[39;00mdataflow():\n",
      "            lv1 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m0\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_matmul_te_broadcast_to_te_ewise_add_te_relu, (X, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m1\u001b[39m], lv1), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv6 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m2\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv1_1 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_matmul_te_broadcast_to_te_ewise_add_te_relu, (lv, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m3\u001b[39m], lv6), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv11 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m4\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv2 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_matmul_te_broadcast_to_te_ewise_add_te_relu, (lv1_1, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m5\u001b[39m], lv11), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv16 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m6\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv3 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_matmul_te_broadcast_to_te_ewise_add_te_relu, (lv2, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m7\u001b[39m], lv16), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv21 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m8\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv4 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_matmul_te_broadcast_to_te_ewise_add_te_relu, (lv3, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m9\u001b[39m], lv21), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            R\u001b[35;01m.\u001b[39;00moutput()\n",
      "        \u001b[32;01mreturn\u001b[39;00m lv4\n",
      "\n",
      "\u001b[90;03m# Metadata omitted. Use show_meta=True in script() method to show it.\u001b[39;00m\n",
      "\n",
      "fusion-only module exported to /content/drive/MyDrive/10714/10714-project/dlsys/apps/models/module_lib/mlp-cpu_fusion.so\n",
      "===== Apply meta_schedule...=====\n",
      "tune_tir_all: target=llvm -num-cores=2\n",
      "  0% 0/3 [00:00<?, ?it/s]tuning: fused_te_matmul_te_broadcast_to_te_ewise_add_te_relu\n",
      "2024-12-09 20:07:45 [INFO] Logging directory: /content/drive/MyDrive/10714/10714-project/dlsys/apps/models/tune_tmp/fused_te_matmul_te_broadcast_to_te_ewise_add_te_relu/logs\n",
      "2024-12-09 20:08:07 [INFO] LocalBuilder: max_workers = 1\n",
      "2024-12-09 20:08:09 [INFO] LocalRunner: max_workers = 1\n",
      "2024-12-09 20:08:12 [INFO] [task_scheduler.cc:159] Initializing Task #0: \"fused_te_matmul_te_broadcast_to_te_ewise_add_te_relu\"\n",
      "2024-12-09 20:08:12 [INFO] [task_scheduler.cc:320] \n",
      " ID |                                                 Name |    FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 | fused_te_matmul_te_broadcast_to_te_ewise_add_te_relu | 4202496 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 0\n",
      "Total latency (us): 0\n",
      "\n",
      "2024-12-09 20:08:12 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: \"fused_te_matmul_te_broadcast_to_te_ewise_add_te_relu\"\n",
      "2024-12-09 20:08:23 [INFO] [task_scheduler.cc:193] Sending 5 sample(s) to builder\n",
      "2024-12-09 20:08:26 [INFO] [task_scheduler.cc:195] Sending 5 sample(s) to runner\n",
      "2024-12-09 20:08:27 [DEBUG] XGB iter   0: tr-p-rmse: 0.422025\ttr-a-peak@32: 1.000000\ttr-rmse: 0.348856\ttr-rmse: 0.348856\n",
      "2024-12-09 20:08:27 [DEBUG] XGB iter  25: tr-p-rmse: 0.068759\ttr-a-peak@32: 1.000000\ttr-rmse: 0.396059\ttr-rmse: 0.396059\n",
      "2024-12-09 20:08:28 [DEBUG] XGB iter  50: tr-p-rmse: 0.068491\ttr-a-peak@32: 1.000000\ttr-rmse: 0.396348\ttr-rmse: 0.396348\n",
      "2024-12-09 20:08:28 [DEBUG] XGB iter  75: tr-p-rmse: 0.068491\ttr-a-peak@32: 1.000000\ttr-rmse: 0.396348\ttr-rmse: 0.396348\n",
      "2024-12-09 20:08:28 [DEBUG] XGB stopped. Best iteration: [41] tr-p-rmse:0.06849\ttr-a-peak@32:1.00000\ttr-rmse:0.39635\ttr-rmse:0.39635 \n",
      "2024-12-09 20:08:28 [INFO] [task_scheduler.cc:237] [Updated] Task #0: \"fused_te_matmul_te_broadcast_to_te_ewise_add_te_relu\"\n",
      "2024-12-09 20:08:28 [INFO] [task_scheduler.cc:320] \n",
      " ID |                                                 Name |    FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 | fused_te_matmul_te_broadcast_to_te_ewise_add_te_relu | 4202496 |      1 |        15.4175 |     272.5792 |              272.5792 |      5 |      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 5\n",
      "Total latency (us): 272.579\n",
      "\n",
      "2024-12-09 20:08:28 [INFO] [task_scheduler.cc:260] Task #0 has finished. Remaining task(s): 0\n",
      "2024-12-09 20:08:28 [INFO] [task_scheduler.cc:320] \n",
      " ID |                                                 Name |    FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0 | fused_te_matmul_te_broadcast_to_te_ewise_add_te_relu | 4202496 |      1 |        15.4175 |     272.5792 |              272.5792 |      5 |    Y \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total trials: 5\n",
      "Total latency (us): 272.579\n",
      "\n",
      " 33% 1/3 [00:42<01:24, 42.44s/it]tuning: main\n",
      "2024-12-09 20:08:28 [INFO] Logging directory: /content/drive/MyDrive/10714/10714-project/dlsys/apps/models/tune_tmp/main/logs\n",
      "tuning: te_reshape\n",
      "2024-12-09 20:08:28 [INFO] Logging directory: /content/drive/MyDrive/10714/10714-project/dlsys/apps/models/tune_tmp/te_reshape/logs\n",
      "2024-12-09 20:08:28 [INFO] LocalBuilder: max_workers = 1\n",
      "2024-12-09 20:08:29 [INFO] LocalRunner: max_workers = 1\n",
      "2024-12-09 20:08:31 [INFO] [task_scheduler.cc:159] Initializing Task #0: \"te_reshape\"\n",
      "2024-12-09 20:08:31 [INFO] [task_scheduler.cc:320] \n",
      " ID |       Name | FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "  0 | te_reshape |    1 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Total trials: 0\n",
      "Total latency (us): 0\n",
      "\n",
      "2024-12-09 20:08:31 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: \"te_reshape\"\n",
      "2024-12-09 20:08:32 [INFO] [task_scheduler.cc:193] Sending 1 sample(s) to builder\n",
      "2024-12-09 20:08:34 [INFO] [task_scheduler.cc:195] Sending 1 sample(s) to runner\n",
      "2024-12-09 20:08:34 [DEBUG] XGB iter   0: tr-p-rmse: 0.450000\ttr-a-peak@32: 1.000000\ttr-rmse: 0.450000\ttr-rmse: 0.450000\n",
      "2024-12-09 20:08:34 [DEBUG] XGB iter  25: tr-p-rmse: 0.032305\ttr-a-peak@32: 1.000000\ttr-rmse: 0.032305\ttr-rmse: 0.032305\n",
      "2024-12-09 20:08:34 [DEBUG] XGB iter  50: tr-p-rmse: 0.002319\ttr-a-peak@32: 1.000000\ttr-rmse: 0.002319\ttr-rmse: 0.002319\n",
      "2024-12-09 20:08:34 [DEBUG] XGB iter  75: tr-p-rmse: 0.000166\ttr-a-peak@32: 1.000000\ttr-rmse: 0.000166\ttr-rmse: 0.000166\n",
      "2024-12-09 20:08:34 [DEBUG] XGB iter 100: tr-p-rmse: 0.000012\ttr-a-peak@32: 1.000000\ttr-rmse: 0.000012\ttr-rmse: 0.000012\n",
      "2024-12-09 20:08:34 [DEBUG] XGB iter 125: tr-p-rmse: 0.000001\ttr-a-peak@32: 1.000000\ttr-rmse: 0.000001\ttr-rmse: 0.000001\n",
      "2024-12-09 20:08:34 [DEBUG] XGB iter 150: tr-p-rmse: 0.000000\ttr-a-peak@32: 1.000000\ttr-rmse: 0.000000\ttr-rmse: 0.000000\n",
      "2024-12-09 20:08:34 [DEBUG] XGB iter 175: tr-p-rmse: 0.000000\ttr-a-peak@32: 1.000000\ttr-rmse: 0.000000\ttr-rmse: 0.000000\n",
      "2024-12-09 20:08:34 [DEBUG] XGB stopped. Best iteration: [131] tr-p-rmse:0.00000\ttr-a-peak@32:1.00000\ttr-rmse:0.00000\ttr-rmse:0.00000 \n",
      "2024-12-09 20:08:34 [INFO] [task_scheduler.cc:237] [Updated] Task #0: \"te_reshape\"\n",
      "2024-12-09 20:08:34 [INFO] [task_scheduler.cc:320] \n",
      " ID |       Name | FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "  0 | te_reshape |    1 |      1 |         0.0002 |       5.3098 |                5.3098 |      1 |      \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Total trials: 1\n",
      "Total latency (us): 5.30981\n",
      "\n",
      "2024-12-09 20:08:34 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: \"te_reshape\"\n",
      "2024-12-09 20:08:36 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder\n",
      "2024-12-09 20:08:36 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner\n",
      "2024-12-09 20:08:36 [INFO] [task_scheduler.cc:237] [Updated] Task #0: \"te_reshape\"\n",
      "2024-12-09 20:08:36 [INFO] [task_scheduler.cc:320] \n",
      " ID |       Name | FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "  0 | te_reshape |    1 |      1 |         0.0002 |       5.3098 |                5.3098 |      1 |      \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Total trials: 1\n",
      "Total latency (us): 5.30981\n",
      "\n",
      "2024-12-09 20:08:36 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: \"te_reshape\"\n",
      "2024-12-09 20:08:37 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder\n",
      "2024-12-09 20:08:37 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner\n",
      "2024-12-09 20:08:37 [INFO] [task_scheduler.cc:237] [Updated] Task #0: \"te_reshape\"\n",
      "2024-12-09 20:08:37 [INFO] [task_scheduler.cc:320] \n",
      " ID |       Name | FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "  0 | te_reshape |    1 |      1 |         0.0002 |       5.3098 |                5.3098 |      1 |      \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Total trials: 1\n",
      "Total latency (us): 5.30981\n",
      "\n",
      "2024-12-09 20:08:37 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: \"te_reshape\"\n",
      "2024-12-09 20:08:39 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder\n",
      "2024-12-09 20:08:39 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner\n",
      "2024-12-09 20:08:39 [INFO] [task_scheduler.cc:237] [Updated] Task #0: \"te_reshape\"\n",
      "2024-12-09 20:08:39 [INFO] [task_scheduler.cc:320] \n",
      " ID |       Name | FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "  0 | te_reshape |    1 |      1 |         0.0002 |       5.3098 |                5.3098 |      1 |      \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Total trials: 1\n",
      "Total latency (us): 5.30981\n",
      "\n",
      "2024-12-09 20:08:39 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: \"te_reshape\"\n",
      "2024-12-09 20:08:41 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder\n",
      "2024-12-09 20:08:41 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner\n",
      "2024-12-09 20:08:41 [INFO] [task_scheduler.cc:237] [Updated] Task #0: \"te_reshape\"\n",
      "2024-12-09 20:08:41 [INFO] [task_scheduler.cc:320] \n",
      " ID |       Name | FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "  0 | te_reshape |    1 |      1 |         0.0002 |       5.3098 |                5.3098 |      1 |      \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Total trials: 1\n",
      "Total latency (us): 5.30981\n",
      "\n",
      "2024-12-09 20:08:41 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: \"te_reshape\"\n",
      "2024-12-09 20:08:42 [INFO] [task_scheduler.cc:260] Task #0 has finished. Remaining task(s): 0\n",
      "2024-12-09 20:08:42 [INFO] [task_scheduler.cc:320] \n",
      " ID |       Name | FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "  0 | te_reshape |    1 |      1 |         0.0002 |       5.3098 |                5.3098 |      1 |    Y \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Total trials: 1\n",
      "Total latency (us): 5.30981\n",
      "\n",
      "100% 3/3 [00:57<00:00, 19.12s/it]\n",
      "===== auto-tuned module =====\n",
      "\u001b[90;03m# from tvm.script import ir as I\u001b[39;00m\n",
      "\u001b[90;03m# from tvm.script import tir as T\u001b[39;00m\n",
      "\u001b[90;03m# from tvm.script import relax as R\u001b[39;00m\n",
      "\n",
      "\u001b[95;03m@I\u001b[39;00m\u001b[35;01m.\u001b[39;00mir_module\n",
      "\u001b[32;01mclass\u001b[39;00m \u001b[34;01mModule\u001b[39;00m:\n",
      "    \u001b[95;03m@T\u001b[39;00m\u001b[35;01m.\u001b[39;00mprim_func\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mfused_te_matmul_te_broadcast_to_te_ewise_add_te_relu\u001b[39;00m(X: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), param_0: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), lv1: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), compute_intermediate: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "        T\u001b[35;01m.\u001b[39;00mfunc_attr({\u001b[33m\"\u001b[39m\u001b[33mtir.noalias\u001b[39m\u001b[33m\"\u001b[39m: T\u001b[35;01m.\u001b[39;00mbool(\u001b[32;01mTrue\u001b[39;00m)})\n",
      "        \u001b[90;03m# with T.block(\"root\"):\u001b[39;00m\n",
      "        T_matmul_intermediate \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00malloc_buffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)))\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0_0_ax1_0_ax0_1_ax1_1_fused \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mparallel(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m)):\n",
      "            \u001b[32;01mfor\u001b[39;00m ax0_2_init, ax1_2_init, ax0_3_init, ax1_3_init \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m128\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m)):\n",
      "                \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_matmul_init\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                    v_ax0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), ax0_0_ax1_0_ax0_1_ax1_1_fused \u001b[35;01m/\u001b[39;00m\u001b[35;01m/\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_2_init \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_3_init)\n",
      "                    v_ax1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax0_0_ax1_0_ax0_1_ax1_1_fused \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m128\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_2_init \u001b[35;01m+\u001b[39;00m ax1_3_init)\n",
      "                    T\u001b[35;01m.\u001b[39;00mreads()\n",
      "                    T\u001b[35;01m.\u001b[39;00mwrites(T_matmul_intermediate[v_ax0, v_ax1])\n",
      "                    T\u001b[35;01m.\u001b[39;00mblock_attr({\u001b[33m\"\u001b[39m\u001b[33mmeta_schedule.tiling_structure\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mSSRSRS\u001b[39m\u001b[33m\"\u001b[39m})\n",
      "                    T_matmul_intermediate[v_ax0, v_ax1] \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00mfloat32(\u001b[92m0.0\u001b[39m)\n",
      "            \u001b[32;01mfor\u001b[39;00m k_0, ax0_2, ax1_2, k_1, ax0_3, ax1_3 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m256\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m128\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m)):\n",
      "                \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_matmul_update\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                    v_ax0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), ax0_0_ax1_0_ax0_1_ax1_1_fused \u001b[35;01m/\u001b[39;00m\u001b[35;01m/\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_3)\n",
      "                    v_ax1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax0_0_ax1_0_ax0_1_ax1_1_fused \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m128\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_2 \u001b[35;01m+\u001b[39;00m ax1_3)\n",
      "                    v_k \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mreduce(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), k_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m k_1)\n",
      "                    T\u001b[35;01m.\u001b[39;00mreads(T_matmul_intermediate[v_ax0, v_ax1], X[v_ax0, v_k], param_0[v_k, v_ax1])\n",
      "                    T\u001b[35;01m.\u001b[39;00mwrites(T_matmul_intermediate[v_ax0, v_ax1])\n",
      "                    T\u001b[35;01m.\u001b[39;00mblock_attr({\u001b[33m\"\u001b[39m\u001b[33mmeta_schedule.tiling_structure\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mSSRSRS\u001b[39m\u001b[33m\"\u001b[39m})\n",
      "                    T_matmul_intermediate[v_ax0, v_ax1] \u001b[35;01m=\u001b[39;00m T_matmul_intermediate[v_ax0, v_ax1] \u001b[35;01m+\u001b[39;00m X[v_ax0, v_k] \u001b[35;01m*\u001b[39;00m param_0[v_k, v_ax1]\n",
      "        \u001b[32;01mfor\u001b[39;00m i0_i1_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mparallel(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m)):\n",
      "            \u001b[32;01mfor\u001b[39;00m i0_i1_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mvectorized(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m)):\n",
      "                \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mcompute\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                    v_i0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), (i0_i1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m i0_i1_fused_1) \u001b[35;01m/\u001b[39;00m\u001b[35;01m/\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    v_i1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), (i0_i1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m i0_i1_fused_1) \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    T\u001b[35;01m.\u001b[39;00mreads(T_matmul_intermediate[v_i0, v_i1], lv1[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v_i1])\n",
      "                    T\u001b[35;01m.\u001b[39;00mwrites(compute_intermediate[v_i0, v_i1])\n",
      "                    compute_intermediate[v_i0, v_i1] \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00mmax(T_matmul_intermediate[v_i0, v_i1] \u001b[35;01m+\u001b[39;00m lv1[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v_i1], T\u001b[35;01m.\u001b[39;00mfloat32(\u001b[92m0.0\u001b[39m))\n",
      "\n",
      "    \u001b[95;03m@T\u001b[39;00m\u001b[35;01m.\u001b[39;00mprim_func\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mte_reshape\u001b[39;00m(A: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), T_reshape: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "        T\u001b[35;01m.\u001b[39;00mfunc_attr({\u001b[33m\"\u001b[39m\u001b[33mop_pattern\u001b[39m\u001b[33m\"\u001b[39m: \u001b[92m2\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtir.noalias\u001b[39m\u001b[33m\"\u001b[39m: T\u001b[35;01m.\u001b[39;00mbool(\u001b[32;01mTrue\u001b[39;00m)})\n",
      "        \u001b[90;03m# with T.block(\"root\"):\u001b[39;00m\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mparallel(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m)):\n",
      "            \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mvectorized(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m)):\n",
      "                \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_reshape\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                    v_ax0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m))\n",
      "                    v_ax1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax0_ax1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_fused_1)\n",
      "                    T\u001b[35;01m.\u001b[39;00mreads(A[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v_ax1 \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)])\n",
      "                    T\u001b[35;01m.\u001b[39;00mwrites(T_reshape[v_ax0, v_ax1])\n",
      "                    T_reshape[v_ax0, v_ax1] \u001b[35;01m=\u001b[39;00m A[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v_ax1 \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)]\n",
      "\n",
      "    \u001b[95;03m@R\u001b[39;00m\u001b[35;01m.\u001b[39;00mfunction\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mmain\u001b[39;00m(X: R\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)) \u001b[35;01m-\u001b[39;00m\u001b[35;01m>\u001b[39;00m R\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "        cls \u001b[35;01m=\u001b[39;00m Module\n",
      "        \u001b[32;01mwith\u001b[39;00m R\u001b[35;01m.\u001b[39;00mdataflow():\n",
      "            lv1 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m0\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_matmul_te_broadcast_to_te_ewise_add_te_relu, (X, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m1\u001b[39m], lv1), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv6 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m2\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv1_1 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_matmul_te_broadcast_to_te_ewise_add_te_relu, (lv, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m3\u001b[39m], lv6), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv11 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m4\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv2 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_matmul_te_broadcast_to_te_ewise_add_te_relu, (lv1_1, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m5\u001b[39m], lv11), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv16 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m6\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv3 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_matmul_te_broadcast_to_te_ewise_add_te_relu, (lv2, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m7\u001b[39m], lv16), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv21 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m8\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv4 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_matmul_te_broadcast_to_te_ewise_add_te_relu, (lv3, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m9\u001b[39m], lv21), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            R\u001b[35;01m.\u001b[39;00moutput()\n",
      "        \u001b[32;01mreturn\u001b[39;00m lv4\n",
      "\n",
      "\u001b[90;03m# Metadata omitted. Use show_meta=True in script() method to show it.\u001b[39;00m\n",
      "\n",
      "fully-optimized module exported to /content/drive/MyDrive/10714/10714-project/dlsys/apps/models/module_lib/mlp-cpu.so\n",
      "module compiled\n",
      "\n",
      "\n",
      "\n",
      " mode=noopt:\n",
      "-------------------------------------------------- \n",
      "AVG NDL TIME: 0.01639095785000791 \tAVG TVM TIME: 0.015684423459993012\n",
      "\n",
      "\n",
      "\n",
      " mode=fusion:\n",
      "-------------------------------------------------- \n",
      "AVG NDL TIME: 0.016079775889988924 \tAVG TVM TIME: 0.015020846650015756\n",
      "\n",
      "\n",
      "\n",
      " mode=optimized:\n",
      "-------------------------------------------------- \n",
      "AVG NDL TIME: 0.01952235253001163 \tAVG TVM TIME: 0.0020836487699921235\n"
     ]
    }
   ],
   "source": [
    "%cd $APP_DIR\n",
    "!python tvm_eval.py -m='mlp' -d='cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4vKq38A-p_n"
   },
   "source": [
    "### Transformer Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKmlE1og-p_n"
   },
   "outputs": [],
   "source": [
    "%cd $APP_DIR\n",
    "!python tvm_eval.py -m='transformer' -d='cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsEAj2XL-p_n"
   },
   "source": [
    "### ResNet9 Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AipT388z-p_n"
   },
   "outputs": [],
   "source": [
    "%cd $APP_DIR\n",
    "!python tvm_eval.py -m='conv' -d='cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lNCoIkS-p_n"
   },
   "source": [
    "# Code Demo: GPU Device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PDlMUjK2-p_n"
   },
   "source": [
    "To check if TVM have `USE_CUDA` turned on. You can run the following command and search for `USE_CUDA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DnozUAVJ-p_r"
   },
   "outputs": [],
   "source": [
    "!python -c \"import tvm; print('\\n'.join(f'{k}: {v}' for k, v in tvm.support.libinfo().items()))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VH6vU1Tt-p_r"
   },
   "source": [
    "### MLP Performance\n",
    "\n",
    "**_Note:_** meta scheduling for `Transformer` and `ResNet9` model might take rounghly **_10-15 minutes_** to finish on the first run. However, since we reload the compiled module executable, the second time would be significantly faster as we bypass the meta scheduler.\n",
    "\n",
    "If you want to recompile the model, add `-r` flag when running `tvm_eval.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32994,
     "status": "ok",
     "timestamp": 1733774993231,
     "user": {
      "displayName": "Vedant Bhasin",
      "userId": "16901580205563811674"
     },
     "user_tz": 300
    },
    "id": "KdsBpnex-p_r",
    "outputId": "dbf8cfc2-d068-4cb4-b883-c5b1651df00b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content/drive/MyDrive/10714/project/dlsys/apps/'\n",
      "/content/drive/MyDrive/10714/10714-project/dlsys/apps\n",
      "Using needle backend\n",
      "tvm_target=cuda: enable dlight.ApplyDefaultSchedule\n",
      "===== original module=====\n",
      "\u001b[90;03m# from tvm.script import ir as I\u001b[39;00m\n",
      "\u001b[90;03m# from tvm.script import tir as T\u001b[39;00m\n",
      "\u001b[90;03m# from tvm.script import relax as R\u001b[39;00m\n",
      "\n",
      "\u001b[95;03m@I\u001b[39;00m\u001b[35;01m.\u001b[39;00mir_module\n",
      "\u001b[32;01mclass\u001b[39;00m \u001b[34;01mModule\u001b[39;00m:\n",
      "    \u001b[95;03m@T\u001b[39;00m\u001b[35;01m.\u001b[39;00mprim_func(private\u001b[35;01m=\u001b[39;00m\u001b[32;01mTrue\u001b[39;00m)\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mte_broadcast_to\u001b[39;00m(lv1: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), T_broadcast_to: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "        T\u001b[35;01m.\u001b[39;00mfunc_attr({\u001b[33m\"\u001b[39m\u001b[33mtir.is_scheduled\u001b[39m\u001b[33m\"\u001b[39m: \u001b[92m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtir.noalias\u001b[39m\u001b[33m\"\u001b[39m: T\u001b[35;01m.\u001b[39;00mbool(\u001b[32;01mTrue\u001b[39;00m)})\n",
      "        \u001b[90;03m# with T.block(\"root\"):\u001b[39;00m\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mblockIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "            \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_broadcast_to\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                    v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), (ax0_ax1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_fused_1) \u001b[35;01m/\u001b[39;00m\u001b[35;01m/\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), (ax0_ax1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_fused_1) \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    T\u001b[35;01m.\u001b[39;00mreads(lv1[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1])\n",
      "                    T\u001b[35;01m.\u001b[39;00mwrites(T_broadcast_to[v0, v1])\n",
      "                    T_broadcast_to[v0, v1] \u001b[35;01m=\u001b[39;00m lv1[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1]\n",
      "\n",
      "    \u001b[95;03m@T\u001b[39;00m\u001b[35;01m.\u001b[39;00mprim_func(private\u001b[35;01m=\u001b[39;00m\u001b[32;01mTrue\u001b[39;00m)\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mte_ewise_add\u001b[39;00m(lv: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), lv2: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), T_add: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "        T\u001b[35;01m.\u001b[39;00mfunc_attr({\u001b[33m\"\u001b[39m\u001b[33mtir.is_scheduled\u001b[39m\u001b[33m\"\u001b[39m: \u001b[92m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtir.noalias\u001b[39m\u001b[33m\"\u001b[39m: T\u001b[35;01m.\u001b[39;00mbool(\u001b[32;01mTrue\u001b[39;00m)})\n",
      "        \u001b[90;03m# with T.block(\"root\"):\u001b[39;00m\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mblockIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "            \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_add\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                    v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), (ax0_ax1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_fused_1) \u001b[35;01m/\u001b[39;00m\u001b[35;01m/\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), (ax0_ax1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_fused_1) \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    T\u001b[35;01m.\u001b[39;00mreads(lv[v0, v1], lv2[v0, v1])\n",
      "                    T\u001b[35;01m.\u001b[39;00mwrites(T_add[v0, v1])\n",
      "                    T_add[v0, v1] \u001b[35;01m=\u001b[39;00m lv[v0, v1] \u001b[35;01m+\u001b[39;00m lv2[v0, v1]\n",
      "\n",
      "    \u001b[95;03m@T\u001b[39;00m\u001b[35;01m.\u001b[39;00mprim_func(private\u001b[35;01m=\u001b[39;00m\u001b[32;01mTrue\u001b[39;00m)\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mte_matmul\u001b[39;00m(X: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), B: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), T_matmul: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "        T\u001b[35;01m.\u001b[39;00mfunc_attr({\u001b[33m\"\u001b[39m\u001b[33mtir.is_scheduled\u001b[39m\u001b[33m\"\u001b[39m: \u001b[92m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtir.noalias\u001b[39m\u001b[33m\"\u001b[39m: T\u001b[35;01m.\u001b[39;00mbool(\u001b[32;01mTrue\u001b[39;00m)})\n",
      "        \u001b[90;03m# with T.block(\"root\"):\u001b[39;00m\n",
      "        T_matmul_reindex_pad_local \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00malloc_buffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), scope\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mlocal\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "        X_reindex_pad_shared \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00malloc_buffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), scope\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mshared\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "        B_reindex_shared \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00malloc_buffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), scope\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mshared\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0_ax2_0_fused \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mblockIdx.y\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "            \u001b[32;01mfor\u001b[39;00m ax1_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mblockIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                \u001b[32;01mfor\u001b[39;00m ax2_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mvthread.y\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                    \u001b[32;01mfor\u001b[39;00m ax1_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mvthread.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                        \u001b[32;01mfor\u001b[39;00m ax2_2 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.y\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                            \u001b[32;01mfor\u001b[39;00m ax1_2 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m, annotations\u001b[35;01m=\u001b[39;00m{\u001b[33m\"\u001b[39m\u001b[33mpragma_auto_unroll_max_step\u001b[39m\u001b[33m\"\u001b[39m: \u001b[92m256\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpragma_unroll_explicit\u001b[39m\u001b[33m\"\u001b[39m: \u001b[92m1\u001b[39m}):\n",
      "                                \u001b[32;01mfor\u001b[39;00m ax1_3_init, ax2_3_0_init \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                    \u001b[32;01mfor\u001b[39;00m ax2_3_1_init \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mvectorized(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                        \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_matmul_init\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                            v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m))\n",
      "                                            v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m), ax1_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_3_init)\n",
      "                                            v2 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax0_ax2_0_fused \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_3_0_init \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_3_1_init)\n",
      "                                            T\u001b[35;01m.\u001b[39;00mreads()\n",
      "                                            T\u001b[35;01m.\u001b[39;00mwrites(T_matmul_reindex_pad_local[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v2])\n",
      "                                            T_matmul_reindex_pad_local[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v2] \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00mfloat32(\u001b[92m0.0\u001b[39m)\n",
      "                                \u001b[32;01mfor\u001b[39;00m ax3_0 \u001b[32;01min\u001b[39;00m range(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m)):\n",
      "                                    \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.y\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                        \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                            \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_2 \u001b[32;01min\u001b[39;00m range(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                                \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_3 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mvectorized(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                                    \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mX_reindex_pad_shared\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                                        v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m))\n",
      "                                                        v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m), (ax0_ax1_ax2_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_3) \u001b[35;01m/\u001b[39;00m\u001b[35;01m/\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m))\n",
      "                                                        v2 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax3_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m) \u001b[35;01m+\u001b[39;00m (ax0_ax1_ax2_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_3) \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m))\n",
      "                                                        T\u001b[35;01m.\u001b[39;00mreads(X[v1, v2])\n",
      "                                                        T\u001b[35;01m.\u001b[39;00mwrites(X_reindex_pad_shared[v0, v1, v2])\n",
      "                                                        T\u001b[35;01m.\u001b[39;00mblock_attr({\u001b[33m\"\u001b[39m\u001b[33mbuffer_dim_align\u001b[39m\u001b[33m\"\u001b[39m: [[\u001b[92m0\u001b[39m, \u001b[92m1\u001b[39m, \u001b[92m8\u001b[39m, \u001b[92m2\u001b[39m]]})\n",
      "                                                        X_reindex_pad_shared[v0, v1, v2] \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00mif_then_else(v1 \u001b[35;01m<\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), X[v1, v2], T\u001b[35;01m.\u001b[39;00mfloat32(\u001b[92m0.0\u001b[39m))\n",
      "                                    \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.y\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                        \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                            \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_2 \u001b[32;01min\u001b[39;00m range(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m)):\n",
      "                                                \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_3 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mvectorized(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                                    \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mB_reindex_shared\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                                        v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m))\n",
      "                                                        v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax0_ax2_0_fused \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m (ax0_ax1_ax2_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_3) \u001b[35;01m/\u001b[39;00m\u001b[35;01m/\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m))\n",
      "                                                        v2 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax3_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m) \u001b[35;01m+\u001b[39;00m (ax0_ax1_ax2_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_3) \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m))\n",
      "                                                        T\u001b[35;01m.\u001b[39;00mreads(B[v2, v1])\n",
      "                                                        T\u001b[35;01m.\u001b[39;00mwrites(B_reindex_shared[v0, v1, v2])\n",
      "                                                        T\u001b[35;01m.\u001b[39;00mblock_attr({\u001b[33m\"\u001b[39m\u001b[33mbuffer_dim_align\u001b[39m\u001b[33m\"\u001b[39m: [[\u001b[92m0\u001b[39m, \u001b[92m1\u001b[39m, \u001b[92m8\u001b[39m, \u001b[92m2\u001b[39m]]})\n",
      "                                                        B_reindex_shared[v0, v1, v2] \u001b[35;01m=\u001b[39;00m B[v2, v1]\n",
      "                                    \u001b[32;01mfor\u001b[39;00m ax3_1, ax1_3, ax2_3_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                        \u001b[32;01mfor\u001b[39;00m ax2_3_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mvectorized(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                            \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_matmul_update\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                                v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m))\n",
      "                                                v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m), ax1_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_3)\n",
      "                                                v2 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax0_ax2_0_fused \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_3_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_3_1)\n",
      "                                                v3 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mreduce(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax3_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m) \u001b[35;01m+\u001b[39;00m ax3_1)\n",
      "                                                T\u001b[35;01m.\u001b[39;00mreads(T_matmul_reindex_pad_local[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v2], X_reindex_pad_shared[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v3], B_reindex_shared[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v2, v3])\n",
      "                                                T\u001b[35;01m.\u001b[39;00mwrites(T_matmul_reindex_pad_local[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v2])\n",
      "                                                T_matmul_reindex_pad_local[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v2] \u001b[35;01m=\u001b[39;00m T_matmul_reindex_pad_local[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v2] \u001b[35;01m+\u001b[39;00m X_reindex_pad_shared[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v3] \u001b[35;01m*\u001b[39;00m B_reindex_shared[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v2, v3]\n",
      "                                \u001b[32;01mfor\u001b[39;00m ax0, ax1, ax2_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                    \u001b[32;01mfor\u001b[39;00m ax2_1_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mvectorized(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                        \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_matmul_reindex_pad_local\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                            v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), ax0)\n",
      "                                            v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m), ax1_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1)\n",
      "                                            v2 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax0_ax2_0_fused \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_1_1)\n",
      "                                            T\u001b[35;01m.\u001b[39;00mwhere(ax1_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1 \u001b[35;01m<\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m))\n",
      "                                            T\u001b[35;01m.\u001b[39;00mreads(T_matmul_reindex_pad_local[v0, v1, v2])\n",
      "                                            T\u001b[35;01m.\u001b[39;00mwrites(T_matmul[v1, v2])\n",
      "                                            T_matmul[v1, v2] \u001b[35;01m=\u001b[39;00m T_matmul_reindex_pad_local[v0, v1, v2]\n",
      "\n",
      "    \u001b[95;03m@T\u001b[39;00m\u001b[35;01m.\u001b[39;00mprim_func(private\u001b[35;01m=\u001b[39;00m\u001b[32;01mTrue\u001b[39;00m)\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mte_relu\u001b[39;00m(lv3: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), compute: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "        T\u001b[35;01m.\u001b[39;00mfunc_attr({\u001b[33m\"\u001b[39m\u001b[33mtir.is_scheduled\u001b[39m\u001b[33m\"\u001b[39m: \u001b[92m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtir.noalias\u001b[39m\u001b[33m\"\u001b[39m: T\u001b[35;01m.\u001b[39;00mbool(\u001b[32;01mTrue\u001b[39;00m)})\n",
      "        \u001b[90;03m# with T.block(\"root\"):\u001b[39;00m\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mblockIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "            \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mcompute\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                    v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), (ax0_ax1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_fused_1) \u001b[35;01m/\u001b[39;00m\u001b[35;01m/\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), (ax0_ax1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_fused_1) \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    T\u001b[35;01m.\u001b[39;00mreads(lv3[v0, v1])\n",
      "                    T\u001b[35;01m.\u001b[39;00mwrites(compute[v0, v1])\n",
      "                    compute[v0, v1] \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00mmax(lv3[v0, v1], T\u001b[35;01m.\u001b[39;00mfloat32(\u001b[92m0.0\u001b[39m))\n",
      "\n",
      "    \u001b[95;03m@T\u001b[39;00m\u001b[35;01m.\u001b[39;00mprim_func(private\u001b[35;01m=\u001b[39;00m\u001b[32;01mTrue\u001b[39;00m)\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mte_reshape\u001b[39;00m(A: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), T_reshape: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "        T\u001b[35;01m.\u001b[39;00mfunc_attr({\u001b[33m\"\u001b[39m\u001b[33mtir.is_scheduled\u001b[39m\u001b[33m\"\u001b[39m: \u001b[92m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtir.noalias\u001b[39m\u001b[33m\"\u001b[39m: T\u001b[35;01m.\u001b[39;00mbool(\u001b[32;01mTrue\u001b[39;00m)})\n",
      "        \u001b[90;03m# with T.block(\"root\"):\u001b[39;00m\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mblockIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "            \u001b[32;01mfor\u001b[39;00m ax0_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_reshape\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                    v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax0_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_fused_1)\n",
      "                    T\u001b[35;01m.\u001b[39;00mwhere(ax0_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_fused_1 \u001b[35;01m<\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    T\u001b[35;01m.\u001b[39;00mreads(A[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v0])\n",
      "                    T\u001b[35;01m.\u001b[39;00mwrites(T_reshape[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v0])\n",
      "                    T_reshape[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v0] \u001b[35;01m=\u001b[39;00m A[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v0]\n",
      "\n",
      "    \u001b[95;03m@R\u001b[39;00m\u001b[35;01m.\u001b[39;00mfunction\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mmain\u001b[39;00m(X: R\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)) \u001b[35;01m-\u001b[39;00m\u001b[35;01m>\u001b[39;00m R\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "        cls \u001b[35;01m=\u001b[39;00m Module\n",
      "        \u001b[32;01mwith\u001b[39;00m R\u001b[35;01m.\u001b[39;00mdataflow():\n",
      "            lv \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (X, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m0\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv1 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m1\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv2 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_broadcast_to, (lv1,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv3 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_ewise_add, (lv, lv2), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv4 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_relu, (lv3,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv5 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (lv4, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m2\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv6 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m3\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv7 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_broadcast_to, (lv6,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv8 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_ewise_add, (lv5, lv7), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv9 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_relu, (lv8,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv10 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (lv9, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m4\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv11 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m5\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv12 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_broadcast_to, (lv11,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv13 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_ewise_add, (lv10, lv12), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv14 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_relu, (lv13,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv15 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (lv14, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m6\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv16 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m7\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv17 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_broadcast_to, (lv16,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv18 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_ewise_add, (lv15, lv17), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv19 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_relu, (lv18,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv20 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (lv19, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m8\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv21 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_reshape, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m9\u001b[39m],), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m1\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv22 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_broadcast_to, (lv21,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv23 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_ewise_add, (lv20, lv22), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv24 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_relu, (lv23,), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            gv: R\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m) \u001b[35;01m=\u001b[39;00m lv24\n",
      "            R\u001b[35;01m.\u001b[39;00moutput(gv)\n",
      "        \u001b[32;01mreturn\u001b[39;00m lv24\n",
      "\n",
      "\u001b[90;03m# Metadata omitted. Use show_meta=True in script() method to show it.\u001b[39;00m\n",
      "\n",
      "noopt module exported to /content/drive/MyDrive/10714/10714-project/dlsys/apps/models/module_lib/mlp-cuda_noopt.so\n",
      "===== transformed module=====\n",
      "\u001b[90;03m# from tvm.script import ir as I\u001b[39;00m\n",
      "\u001b[90;03m# from tvm.script import tir as T\u001b[39;00m\n",
      "\u001b[90;03m# from tvm.script import relax as R\u001b[39;00m\n",
      "\n",
      "\u001b[95;03m@I\u001b[39;00m\u001b[35;01m.\u001b[39;00mir_module\n",
      "\u001b[32;01mclass\u001b[39;00m \u001b[34;01mModule\u001b[39;00m:\n",
      "    \u001b[95;03m@T\u001b[39;00m\u001b[35;01m.\u001b[39;00mprim_func(private\u001b[35;01m=\u001b[39;00m\u001b[32;01mTrue\u001b[39;00m)\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mfused_te_reshape_te_broadcast_to_te_ewise_add_te_relu\u001b[39;00m(param_0: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), lv: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), compute_intermediate: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "        T\u001b[35;01m.\u001b[39;00mfunc_attr({\u001b[33m\"\u001b[39m\u001b[33mtir.noalias\u001b[39m\u001b[33m\"\u001b[39m: T\u001b[35;01m.\u001b[39;00mbool(\u001b[32;01mTrue\u001b[39;00m)})\n",
      "        \u001b[90;03m# with T.block(\"root\"):\u001b[39;00m\n",
      "        T_reshape_intermediate \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00malloc_buffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)))\n",
      "        T_broadcast_to_intermediate \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00malloc_buffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)))\n",
      "        T_add_intermediate \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00malloc_buffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)))\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mblockIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "            \u001b[32;01mfor\u001b[39;00m ax0_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_reshape\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                    v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax0_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_fused_1)\n",
      "                    T\u001b[35;01m.\u001b[39;00mwhere(ax0_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_fused_1 \u001b[35;01m<\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    T\u001b[35;01m.\u001b[39;00mreads(param_0[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v0])\n",
      "                    T\u001b[35;01m.\u001b[39;00mwrites(T_reshape_intermediate[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v0])\n",
      "                    T_reshape_intermediate[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v0] \u001b[35;01m=\u001b[39;00m param_0[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v0]\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mblockIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "            \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_broadcast_to\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                    v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), (ax0_ax1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_fused_1) \u001b[35;01m/\u001b[39;00m\u001b[35;01m/\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), (ax0_ax1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_fused_1) \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    T\u001b[35;01m.\u001b[39;00mreads(T_reshape_intermediate[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1])\n",
      "                    T\u001b[35;01m.\u001b[39;00mwrites(T_broadcast_to_intermediate[v0, v1])\n",
      "                    T_broadcast_to_intermediate[v0, v1] \u001b[35;01m=\u001b[39;00m T_reshape_intermediate[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1]\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mblockIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "            \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_add\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                    v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), (ax0_ax1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_fused_1) \u001b[35;01m/\u001b[39;00m\u001b[35;01m/\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), (ax0_ax1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_fused_1) \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    T\u001b[35;01m.\u001b[39;00mreads(lv[v0, v1], T_broadcast_to_intermediate[v0, v1])\n",
      "                    T\u001b[35;01m.\u001b[39;00mwrites(T_add_intermediate[v0, v1])\n",
      "                    T_add_intermediate[v0, v1] \u001b[35;01m=\u001b[39;00m lv[v0, v1] \u001b[35;01m+\u001b[39;00m T_broadcast_to_intermediate[v0, v1]\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mblockIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "            \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mcompute\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                    v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), (ax0_ax1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_fused_1) \u001b[35;01m/\u001b[39;00m\u001b[35;01m/\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), (ax0_ax1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_fused_1) \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    T\u001b[35;01m.\u001b[39;00mreads(T_add_intermediate[v0, v1])\n",
      "                    T\u001b[35;01m.\u001b[39;00mwrites(compute_intermediate[v0, v1])\n",
      "                    compute_intermediate[v0, v1] \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00mmax(T_add_intermediate[v0, v1], T\u001b[35;01m.\u001b[39;00mfloat32(\u001b[92m0.0\u001b[39m))\n",
      "\n",
      "    \u001b[95;03m@T\u001b[39;00m\u001b[35;01m.\u001b[39;00mprim_func(private\u001b[35;01m=\u001b[39;00m\u001b[32;01mTrue\u001b[39;00m)\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mte_matmul\u001b[39;00m(X: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), B: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), T_matmul: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "        T\u001b[35;01m.\u001b[39;00mfunc_attr({\u001b[33m\"\u001b[39m\u001b[33mop_pattern\u001b[39m\u001b[33m\"\u001b[39m: \u001b[92m8\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtir.is_scheduled\u001b[39m\u001b[33m\"\u001b[39m: \u001b[92m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtir.noalias\u001b[39m\u001b[33m\"\u001b[39m: T\u001b[35;01m.\u001b[39;00mbool(\u001b[32;01mTrue\u001b[39;00m)})\n",
      "        \u001b[90;03m# with T.block(\"root\"):\u001b[39;00m\n",
      "        T_matmul_reindex_pad_local \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00malloc_buffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), scope\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mlocal\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "        X_reindex_pad_shared \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00malloc_buffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), scope\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mshared\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "        B_reindex_shared \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00malloc_buffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), scope\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mshared\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0_ax2_0_fused \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mblockIdx.y\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "            \u001b[32;01mfor\u001b[39;00m ax1_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mblockIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                \u001b[32;01mfor\u001b[39;00m ax2_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mvthread.y\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                    \u001b[32;01mfor\u001b[39;00m ax1_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mvthread.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                        \u001b[32;01mfor\u001b[39;00m ax2_2 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.y\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                            \u001b[32;01mfor\u001b[39;00m ax1_2 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m, annotations\u001b[35;01m=\u001b[39;00m{\u001b[33m\"\u001b[39m\u001b[33mpragma_auto_unroll_max_step\u001b[39m\u001b[33m\"\u001b[39m: \u001b[92m256\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpragma_unroll_explicit\u001b[39m\u001b[33m\"\u001b[39m: \u001b[92m1\u001b[39m}):\n",
      "                                \u001b[32;01mfor\u001b[39;00m ax1_3_init, ax2_3_0_init \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                    \u001b[32;01mfor\u001b[39;00m ax2_3_1_init \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mvectorized(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                        \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_matmul_init\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                            v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m))\n",
      "                                            v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m), ax1_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_3_init)\n",
      "                                            v2 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax0_ax2_0_fused \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_3_0_init \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_3_1_init)\n",
      "                                            T\u001b[35;01m.\u001b[39;00mreads()\n",
      "                                            T\u001b[35;01m.\u001b[39;00mwrites(T_matmul_reindex_pad_local[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v2])\n",
      "                                            T_matmul_reindex_pad_local[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v2] \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00mfloat32(\u001b[92m0.0\u001b[39m)\n",
      "                                \u001b[32;01mfor\u001b[39;00m ax3_0 \u001b[32;01min\u001b[39;00m range(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m)):\n",
      "                                    \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.y\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                        \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                            \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_2 \u001b[32;01min\u001b[39;00m range(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                                \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_3 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mvectorized(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                                    \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mX_reindex_pad_shared\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                                        v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m))\n",
      "                                                        v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m), (ax0_ax1_ax2_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_3) \u001b[35;01m/\u001b[39;00m\u001b[35;01m/\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m))\n",
      "                                                        v2 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax3_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m) \u001b[35;01m+\u001b[39;00m (ax0_ax1_ax2_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_3) \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m))\n",
      "                                                        T\u001b[35;01m.\u001b[39;00mreads(X[v1, v2])\n",
      "                                                        T\u001b[35;01m.\u001b[39;00mwrites(X_reindex_pad_shared[v0, v1, v2])\n",
      "                                                        T\u001b[35;01m.\u001b[39;00mblock_attr({\u001b[33m\"\u001b[39m\u001b[33mbuffer_dim_align\u001b[39m\u001b[33m\"\u001b[39m: [[\u001b[92m0\u001b[39m, \u001b[92m1\u001b[39m, \u001b[92m8\u001b[39m, \u001b[92m2\u001b[39m]]})\n",
      "                                                        X_reindex_pad_shared[v0, v1, v2] \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00mif_then_else(v1 \u001b[35;01m<\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), X[v1, v2], T\u001b[35;01m.\u001b[39;00mfloat32(\u001b[92m0.0\u001b[39m))\n",
      "                                    \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.y\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                        \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                            \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_2 \u001b[32;01min\u001b[39;00m range(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m)):\n",
      "                                                \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_3 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mvectorized(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                                    \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mB_reindex_shared\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                                        v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m))\n",
      "                                                        v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax0_ax2_0_fused \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m (ax0_ax1_ax2_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_3) \u001b[35;01m/\u001b[39;00m\u001b[35;01m/\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m))\n",
      "                                                        v2 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax3_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m) \u001b[35;01m+\u001b[39;00m (ax0_ax1_ax2_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_3) \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m))\n",
      "                                                        T\u001b[35;01m.\u001b[39;00mreads(B[v2, v1])\n",
      "                                                        T\u001b[35;01m.\u001b[39;00mwrites(B_reindex_shared[v0, v1, v2])\n",
      "                                                        T\u001b[35;01m.\u001b[39;00mblock_attr({\u001b[33m\"\u001b[39m\u001b[33mbuffer_dim_align\u001b[39m\u001b[33m\"\u001b[39m: [[\u001b[92m0\u001b[39m, \u001b[92m1\u001b[39m, \u001b[92m8\u001b[39m, \u001b[92m2\u001b[39m]]})\n",
      "                                                        B_reindex_shared[v0, v1, v2] \u001b[35;01m=\u001b[39;00m B[v2, v1]\n",
      "                                    \u001b[32;01mfor\u001b[39;00m ax3_1, ax1_3, ax2_3_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                        \u001b[32;01mfor\u001b[39;00m ax2_3_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mvectorized(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                            \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_matmul_update\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                                v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m))\n",
      "                                                v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m), ax1_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_3)\n",
      "                                                v2 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax0_ax2_0_fused \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_3_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_3_1)\n",
      "                                                v3 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mreduce(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax3_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m) \u001b[35;01m+\u001b[39;00m ax3_1)\n",
      "                                                T\u001b[35;01m.\u001b[39;00mreads(T_matmul_reindex_pad_local[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v2], X_reindex_pad_shared[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v3], B_reindex_shared[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v2, v3])\n",
      "                                                T\u001b[35;01m.\u001b[39;00mwrites(T_matmul_reindex_pad_local[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v2])\n",
      "                                                T_matmul_reindex_pad_local[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v2] \u001b[35;01m=\u001b[39;00m T_matmul_reindex_pad_local[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v2] \u001b[35;01m+\u001b[39;00m X_reindex_pad_shared[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v3] \u001b[35;01m*\u001b[39;00m B_reindex_shared[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v2, v3]\n",
      "                                \u001b[32;01mfor\u001b[39;00m ax0, ax1, ax2_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                    \u001b[32;01mfor\u001b[39;00m ax2_1_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mvectorized(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                        \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_matmul_reindex_pad_local\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                            v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), ax0)\n",
      "                                            v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m), ax1_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1)\n",
      "                                            v2 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax0_ax2_0_fused \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_1_1)\n",
      "                                            T\u001b[35;01m.\u001b[39;00mwhere(ax1_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1 \u001b[35;01m<\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m))\n",
      "                                            T\u001b[35;01m.\u001b[39;00mreads(T_matmul_reindex_pad_local[v0, v1, v2])\n",
      "                                            T\u001b[35;01m.\u001b[39;00mwrites(T_matmul[v1, v2])\n",
      "                                            T_matmul[v1, v2] \u001b[35;01m=\u001b[39;00m T_matmul_reindex_pad_local[v0, v1, v2]\n",
      "\n",
      "    \u001b[95;03m@R\u001b[39;00m\u001b[35;01m.\u001b[39;00mfunction\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mmain\u001b[39;00m(X: R\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)) \u001b[35;01m-\u001b[39;00m\u001b[35;01m>\u001b[39;00m R\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "        cls \u001b[35;01m=\u001b[39;00m Module\n",
      "        \u001b[32;01mwith\u001b[39;00m R\u001b[35;01m.\u001b[39;00mdataflow():\n",
      "            lv \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (X, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m0\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv_1 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_reshape_te_broadcast_to_te_ewise_add_te_relu, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m1\u001b[39m], lv), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv5 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (lv_1, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m2\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv1 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_reshape_te_broadcast_to_te_ewise_add_te_relu, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m3\u001b[39m], lv5), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv10 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (lv1, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m4\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv2 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_reshape_te_broadcast_to_te_ewise_add_te_relu, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m5\u001b[39m], lv10), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv15 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (lv2, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m6\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv3 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_reshape_te_broadcast_to_te_ewise_add_te_relu, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m7\u001b[39m], lv15), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv20 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (lv3, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m8\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv4 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_reshape_te_broadcast_to_te_ewise_add_te_relu, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m9\u001b[39m], lv20), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            R\u001b[35;01m.\u001b[39;00moutput()\n",
      "        \u001b[32;01mreturn\u001b[39;00m lv4\n",
      "\n",
      "\u001b[90;03m# Metadata omitted. Use show_meta=True in script() method to show it.\u001b[39;00m\n",
      "\n",
      "fusion-only module exported to /content/drive/MyDrive/10714/10714-project/dlsys/apps/models/module_lib/mlp-cuda_fusion.so\n",
      "===== Apply meta_schedule...=====\n",
      "tune_tir_all: target=cuda -arch=sm_75\n",
      "  0% 0/3 [00:00<?, ?it/s]tuning: fused_te_reshape_te_broadcast_to_te_ewise_add_te_relu\n",
      "2024-12-09 20:09:26 [INFO] Logging directory: /content/drive/MyDrive/10714/10714-project/dlsys/apps/models/tune_tmp/fused_te_reshape_te_broadcast_to_te_ewise_add_te_relu/logs\n",
      " 33% 1/3 [00:22<00:45, 22.65s/it]tuning: main\n",
      "2024-12-09 20:09:49 [INFO] Logging directory: /content/drive/MyDrive/10714/10714-project/dlsys/apps/models/tune_tmp/main/logs\n",
      "tuning: te_matmul\n",
      "2024-12-09 20:09:49 [INFO] Logging directory: /content/drive/MyDrive/10714/10714-project/dlsys/apps/models/tune_tmp/te_matmul/logs\n",
      "100% 3/3 [00:22<00:00,  7.56s/it]\n",
      "===== auto-tuned module =====\n",
      "\u001b[90;03m# from tvm.script import ir as I\u001b[39;00m\n",
      "\u001b[90;03m# from tvm.script import tir as T\u001b[39;00m\n",
      "\u001b[90;03m# from tvm.script import relax as R\u001b[39;00m\n",
      "\n",
      "\u001b[95;03m@I\u001b[39;00m\u001b[35;01m.\u001b[39;00mir_module\n",
      "\u001b[32;01mclass\u001b[39;00m \u001b[34;01mModule\u001b[39;00m:\n",
      "    \u001b[95;03m@T\u001b[39;00m\u001b[35;01m.\u001b[39;00mprim_func(private\u001b[35;01m=\u001b[39;00m\u001b[32;01mTrue\u001b[39;00m)\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mfused_te_reshape_te_broadcast_to_te_ewise_add_te_relu\u001b[39;00m(param_0: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), lv: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), compute_intermediate: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "        T\u001b[35;01m.\u001b[39;00mfunc_attr({\u001b[33m\"\u001b[39m\u001b[33mtir.noalias\u001b[39m\u001b[33m\"\u001b[39m: T\u001b[35;01m.\u001b[39;00mbool(\u001b[32;01mTrue\u001b[39;00m)})\n",
      "        \u001b[90;03m# with T.block(\"root\"):\u001b[39;00m\n",
      "        T_reshape_intermediate \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00malloc_buffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)))\n",
      "        T_broadcast_to_intermediate \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00malloc_buffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)))\n",
      "        T_add_intermediate \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00malloc_buffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)))\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mblockIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "            \u001b[32;01mfor\u001b[39;00m ax0_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_reshape\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                    v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax0_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_fused_1)\n",
      "                    T\u001b[35;01m.\u001b[39;00mwhere(ax0_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_fused_1 \u001b[35;01m<\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    T\u001b[35;01m.\u001b[39;00mreads(param_0[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v0])\n",
      "                    T\u001b[35;01m.\u001b[39;00mwrites(T_reshape_intermediate[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v0])\n",
      "                    T_reshape_intermediate[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v0] \u001b[35;01m=\u001b[39;00m param_0[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v0]\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mblockIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "            \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_broadcast_to\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                    v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), (ax0_ax1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_fused_1) \u001b[35;01m/\u001b[39;00m\u001b[35;01m/\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), (ax0_ax1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_fused_1) \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    T\u001b[35;01m.\u001b[39;00mreads(T_reshape_intermediate[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1])\n",
      "                    T\u001b[35;01m.\u001b[39;00mwrites(T_broadcast_to_intermediate[v0, v1])\n",
      "                    T_broadcast_to_intermediate[v0, v1] \u001b[35;01m=\u001b[39;00m T_reshape_intermediate[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1]\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mblockIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "            \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_add\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                    v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), (ax0_ax1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_fused_1) \u001b[35;01m/\u001b[39;00m\u001b[35;01m/\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), (ax0_ax1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_fused_1) \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    T\u001b[35;01m.\u001b[39;00mreads(lv[v0, v1], T_broadcast_to_intermediate[v0, v1])\n",
      "                    T\u001b[35;01m.\u001b[39;00mwrites(T_add_intermediate[v0, v1])\n",
      "                    T_add_intermediate[v0, v1] \u001b[35;01m=\u001b[39;00m lv[v0, v1] \u001b[35;01m+\u001b[39;00m T_broadcast_to_intermediate[v0, v1]\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mblockIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "            \u001b[32;01mfor\u001b[39;00m ax0_ax1_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mcompute\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                    v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), (ax0_ax1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_fused_1) \u001b[35;01m/\u001b[39;00m\u001b[35;01m/\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), (ax0_ax1_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1024\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_fused_1) \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m))\n",
      "                    T\u001b[35;01m.\u001b[39;00mreads(T_add_intermediate[v0, v1])\n",
      "                    T\u001b[35;01m.\u001b[39;00mwrites(compute_intermediate[v0, v1])\n",
      "                    compute_intermediate[v0, v1] \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00mmax(T_add_intermediate[v0, v1], T\u001b[35;01m.\u001b[39;00mfloat32(\u001b[92m0.0\u001b[39m))\n",
      "\n",
      "    \u001b[95;03m@T\u001b[39;00m\u001b[35;01m.\u001b[39;00mprim_func(private\u001b[35;01m=\u001b[39;00m\u001b[32;01mTrue\u001b[39;00m)\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mte_matmul\u001b[39;00m(X: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), B: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), T_matmul: T\u001b[35;01m.\u001b[39;00mBuffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "        T\u001b[35;01m.\u001b[39;00mfunc_attr({\u001b[33m\"\u001b[39m\u001b[33mop_pattern\u001b[39m\u001b[33m\"\u001b[39m: \u001b[92m8\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtir.is_scheduled\u001b[39m\u001b[33m\"\u001b[39m: \u001b[92m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtir.noalias\u001b[39m\u001b[33m\"\u001b[39m: T\u001b[35;01m.\u001b[39;00mbool(\u001b[32;01mTrue\u001b[39;00m)})\n",
      "        \u001b[90;03m# with T.block(\"root\"):\u001b[39;00m\n",
      "        T_matmul_reindex_pad_local \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00malloc_buffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), scope\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mlocal\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "        X_reindex_pad_shared \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00malloc_buffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), scope\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mshared\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "        B_reindex_shared \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00malloc_buffer((T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m)), scope\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mshared\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "        \u001b[32;01mfor\u001b[39;00m ax0_ax2_0_fused \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mblockIdx.y\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "            \u001b[32;01mfor\u001b[39;00m ax1_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mblockIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                \u001b[32;01mfor\u001b[39;00m ax2_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mvthread.y\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                    \u001b[32;01mfor\u001b[39;00m ax1_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mvthread.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                        \u001b[32;01mfor\u001b[39;00m ax2_2 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.y\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                            \u001b[32;01mfor\u001b[39;00m ax1_2 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m, annotations\u001b[35;01m=\u001b[39;00m{\u001b[33m\"\u001b[39m\u001b[33mpragma_auto_unroll_max_step\u001b[39m\u001b[33m\"\u001b[39m: \u001b[92m256\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpragma_unroll_explicit\u001b[39m\u001b[33m\"\u001b[39m: \u001b[92m1\u001b[39m}):\n",
      "                                \u001b[32;01mfor\u001b[39;00m ax1_3_init, ax2_3_0_init \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                    \u001b[32;01mfor\u001b[39;00m ax2_3_1_init \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mvectorized(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                        \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_matmul_init\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                            v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m))\n",
      "                                            v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m), ax1_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_3_init)\n",
      "                                            v2 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax0_ax2_0_fused \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_3_0_init \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_3_1_init)\n",
      "                                            T\u001b[35;01m.\u001b[39;00mreads()\n",
      "                                            T\u001b[35;01m.\u001b[39;00mwrites(T_matmul_reindex_pad_local[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v2])\n",
      "                                            T_matmul_reindex_pad_local[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v2] \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00mfloat32(\u001b[92m0.0\u001b[39m)\n",
      "                                \u001b[32;01mfor\u001b[39;00m ax3_0 \u001b[32;01min\u001b[39;00m range(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m)):\n",
      "                                    \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.y\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                        \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                            \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_2 \u001b[32;01min\u001b[39;00m range(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                                \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_3 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mvectorized(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                                    \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mX_reindex_pad_shared\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                                        v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m))\n",
      "                                                        v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m), (ax0_ax1_ax2_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_3) \u001b[35;01m/\u001b[39;00m\u001b[35;01m/\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m))\n",
      "                                                        v2 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax3_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m) \u001b[35;01m+\u001b[39;00m (ax0_ax1_ax2_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_3) \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m))\n",
      "                                                        T\u001b[35;01m.\u001b[39;00mreads(X[v1, v2])\n",
      "                                                        T\u001b[35;01m.\u001b[39;00mwrites(X_reindex_pad_shared[v0, v1, v2])\n",
      "                                                        T\u001b[35;01m.\u001b[39;00mblock_attr({\u001b[33m\"\u001b[39m\u001b[33mbuffer_dim_align\u001b[39m\u001b[33m\"\u001b[39m: [[\u001b[92m0\u001b[39m, \u001b[92m1\u001b[39m, \u001b[92m8\u001b[39m, \u001b[92m2\u001b[39m]]})\n",
      "                                                        X_reindex_pad_shared[v0, v1, v2] \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00mif_then_else(v1 \u001b[35;01m<\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), X[v1, v2], T\u001b[35;01m.\u001b[39;00mfloat32(\u001b[92m0.0\u001b[39m))\n",
      "                                    \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.y\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                        \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mthread_binding(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m), thread\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mthreadIdx.x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                            \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_2 \u001b[32;01min\u001b[39;00m range(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m)):\n",
      "                                                \u001b[32;01mfor\u001b[39;00m ax0_ax1_ax2_fused_3 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mvectorized(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                                    \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mB_reindex_shared\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                                        v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m))\n",
      "                                                        v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax0_ax2_0_fused \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m (ax0_ax1_ax2_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_3) \u001b[35;01m/\u001b[39;00m\u001b[35;01m/\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m))\n",
      "                                                        v2 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax3_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m) \u001b[35;01m+\u001b[39;00m (ax0_ax1_ax2_fused_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax0_ax1_ax2_fused_3) \u001b[35;01m%\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m))\n",
      "                                                        T\u001b[35;01m.\u001b[39;00mreads(B[v2, v1])\n",
      "                                                        T\u001b[35;01m.\u001b[39;00mwrites(B_reindex_shared[v0, v1, v2])\n",
      "                                                        T\u001b[35;01m.\u001b[39;00mblock_attr({\u001b[33m\"\u001b[39m\u001b[33mbuffer_dim_align\u001b[39m\u001b[33m\"\u001b[39m: [[\u001b[92m0\u001b[39m, \u001b[92m1\u001b[39m, \u001b[92m8\u001b[39m, \u001b[92m2\u001b[39m]]})\n",
      "                                                        B_reindex_shared[v0, v1, v2] \u001b[35;01m=\u001b[39;00m B[v2, v1]\n",
      "                                    \u001b[32;01mfor\u001b[39;00m ax3_1, ax1_3, ax2_3_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                        \u001b[32;01mfor\u001b[39;00m ax2_3_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mvectorized(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                            \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_matmul_update\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                                v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m))\n",
      "                                                v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m), ax1_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1_3)\n",
      "                                                v2 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax0_ax2_0_fused \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_1 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_3_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_3_1)\n",
      "                                                v3 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mreduce(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax3_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m16\u001b[39m) \u001b[35;01m+\u001b[39;00m ax3_1)\n",
      "                                                T\u001b[35;01m.\u001b[39;00mreads(T_matmul_reindex_pad_local[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v2], X_reindex_pad_shared[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v3], B_reindex_shared[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v2, v3])\n",
      "                                                T\u001b[35;01m.\u001b[39;00mwrites(T_matmul_reindex_pad_local[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v2])\n",
      "                                                T_matmul_reindex_pad_local[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v2] \u001b[35;01m=\u001b[39;00m T_matmul_reindex_pad_local[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v2] \u001b[35;01m+\u001b[39;00m X_reindex_pad_shared[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v1, v3] \u001b[35;01m*\u001b[39;00m B_reindex_shared[T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m0\u001b[39m), v2, v3]\n",
      "                                \u001b[32;01mfor\u001b[39;00m ax0, ax1, ax2_0 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mgrid(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m), T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                    \u001b[32;01mfor\u001b[39;00m ax2_1_1 \u001b[32;01min\u001b[39;00m T\u001b[35;01m.\u001b[39;00mvectorized(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m)):\n",
      "                                        \u001b[32;01mwith\u001b[39;00m T\u001b[35;01m.\u001b[39;00mblock(\u001b[33m\"\u001b[39m\u001b[33mT_matmul_reindex_pad_local\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "                                            v0 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m1\u001b[39m), ax0)\n",
      "                                            v1 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m32\u001b[39m), ax1_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1)\n",
      "                                            v2 \u001b[35;01m=\u001b[39;00m T\u001b[35;01m.\u001b[39;00maxis\u001b[35;01m.\u001b[39;00mspatial(T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m512\u001b[39m), ax0_ax2_0_fused \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m64\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_0 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m2\u001b[39m) \u001b[35;01m+\u001b[39;00m ax2_1_1)\n",
      "                                            T\u001b[35;01m.\u001b[39;00mwhere(ax1_2 \u001b[35;01m*\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m4\u001b[39m) \u001b[35;01m+\u001b[39;00m ax1 \u001b[35;01m<\u001b[39;00m T\u001b[35;01m.\u001b[39;00mint64(\u001b[92m8\u001b[39m))\n",
      "                                            T\u001b[35;01m.\u001b[39;00mreads(T_matmul_reindex_pad_local[v0, v1, v2])\n",
      "                                            T\u001b[35;01m.\u001b[39;00mwrites(T_matmul[v1, v2])\n",
      "                                            T_matmul[v1, v2] \u001b[35;01m=\u001b[39;00m T_matmul_reindex_pad_local[v0, v1, v2]\n",
      "\n",
      "    \u001b[95;03m@R\u001b[39;00m\u001b[35;01m.\u001b[39;00mfunction\n",
      "    \u001b[32;01mdef\u001b[39;00m \u001b[34;01mmain\u001b[39;00m(X: R\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)) \u001b[35;01m-\u001b[39;00m\u001b[35;01m>\u001b[39;00m R\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "        cls \u001b[35;01m=\u001b[39;00m Module\n",
      "        \u001b[32;01mwith\u001b[39;00m R\u001b[35;01m.\u001b[39;00mdataflow():\n",
      "            lv \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (X, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m0\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv_1 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_reshape_te_broadcast_to_te_ewise_add_te_relu, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m1\u001b[39m], lv), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv5 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (lv_1, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m2\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv1 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_reshape_te_broadcast_to_te_ewise_add_te_relu, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m3\u001b[39m], lv5), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv10 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (lv1, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m4\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv2 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_reshape_te_broadcast_to_te_ewise_add_te_relu, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m5\u001b[39m], lv10), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv15 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (lv2, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m6\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv3 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_reshape_te_broadcast_to_te_ewise_add_te_relu, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m7\u001b[39m], lv15), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv20 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mte_matmul, (lv3, metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m8\u001b[39m]), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            lv4 \u001b[35;01m=\u001b[39;00m R\u001b[35;01m.\u001b[39;00mcall_tir(cls\u001b[35;01m.\u001b[39;00mfused_te_reshape_te_broadcast_to_te_ewise_add_te_relu, (metadata[\u001b[33m\"\u001b[39m\u001b[33mrelax.expr.Constant\u001b[39m\u001b[33m\"\u001b[39m][\u001b[92m9\u001b[39m], lv20), out_sinfo\u001b[35;01m=\u001b[39;00mR\u001b[35;01m.\u001b[39;00mTensor((\u001b[92m8\u001b[39m, \u001b[92m512\u001b[39m), dtype\u001b[35;01m=\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "            R\u001b[35;01m.\u001b[39;00moutput()\n",
      "        \u001b[32;01mreturn\u001b[39;00m lv4\n",
      "\n",
      "\u001b[90;03m# Metadata omitted. Use show_meta=True in script() method to show it.\u001b[39;00m\n",
      "\n",
      "fully-optimized module exported to /content/drive/MyDrive/10714/10714-project/dlsys/apps/models/module_lib/mlp-cuda.so\n",
      "module compiled\n",
      "\n",
      "\n",
      "\n",
      " mode=noopt:\n",
      "-------------------------------------------------- \n",
      "AVG NDL TIME: 0.0016288594699835812 \tAVG TVM TIME: 0.0001521991699883074\n",
      "\n",
      "\n",
      "\n",
      " mode=fusion:\n",
      "-------------------------------------------------- \n",
      "AVG NDL TIME: 0.0011669314699884125 \tAVG TVM TIME: 0.00013535676000628883\n",
      "\n",
      "\n",
      "\n",
      " mode=optimized:\n",
      "-------------------------------------------------- \n",
      "AVG NDL TIME: 0.0009483645399996022 \tAVG TVM TIME: 0.00014119503999154403\n"
     ]
    }
   ],
   "source": [
    "%cd $APP_DIR\n",
    "!python tvm_eval.py -m='mlp' -d='cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21245Ah0-p_r"
   },
   "source": [
    "### Transformer Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aIUZ2kKx-p_2"
   },
   "outputs": [],
   "source": [
    "%cd $APP_DIR\n",
    "!python tvm_eval.py -m='transformer' -d='cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQTsO3wn-p_2"
   },
   "source": [
    "### Resnet9 Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mUcNloGp-p_2"
   },
   "outputs": [],
   "source": [
    "%cd $APP_DIR\n",
    "!python tvm_eval.py -m='conv' -d='cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FlnNZcb-p_2"
   },
   "source": [
    "# Result Analysis\n",
    "#### CPU\n",
    "\n",
    "The results showcase the performance improvements on Intel(R) Xeon(R) CPU (Google Colab environment) achieved through various levels of TVM optimizations on three models: MLP, Transformer, and Conv ResNet9. The key takeaways from the analysis are as follows:\n",
    "\n",
    "| Model        | Needle (Baseline) | TVM (no opt) | TVM (Fusion) | TVM (Fusion + Autotune) |\n",
    "| ------------ | ----------------- | ------------ | ------------ | ----------------------- |\n",
    "| MLP          | 1                 | 1.044256574  | 0.9039618473 | 0.08090549938           |\n",
    "| Transformer  | 1                 | 1.139139027  | 1.124182424  | 0.1171342219            |\n",
    "| Conv ResNet9 | 1                 | 0.3264763352 | 0.3361647851 | 0.1040680634            |\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"./images/cpu_benchmark.png\" alt=\"CPU Benchmark Results\" width=\"70%\">\n",
    "</div>\n",
    "\n",
    "## Explanation\n",
    "\n",
    "**TVM without any optimizations** demonstrates no significant execution time gains for MLP and Transformer models, with MLP showing a slight performance drop (1.04x baseline) and Transformer experiencing a minor slowdown (1.14x baseline). However, Conv ResNet9 benefits considerably, achieving a substantial improvement (0.33x baseline). This discrepancy suggests that while TVM's default handling of tensor operations in the relax framework may implicitly optimize convolution-heavy models like Conv ResNet9, it does not provide similar benefits for fully connected or attention-based models, which rely on different operation patterns.\n",
    "\n",
    "**Operator fusion in TVM** results in modest performance improvements, with mixed outcomes across models. For MLP, there is a slight improvement compared to TVM without optimizations and the baseline, achieving 0.90x baseline performance, but the gain remains limited and far from optimal. For the Transformer, the result is marginally better than TVM with no optimizations (1.12x baseline) but still underperforms compared to the baseline. Conv ResNet9 shows performance similar to TVM without optimization. These results suggest that while operator fusion has potential, its current implementation has limitations, and we aim to revisit and refine the operation fusion design as part of future work.\n",
    "\n",
    "**Combining fusion with autotuning in TVM** results in substantial performance improvements for all models. MLP achieves a remarkable speedup, running at just 0.08x Needle runtime, translating to over 12x faster performance, demonstrating the effectiveness of fine-grained operator tuning. The Transformer sees significant gains, with a runtime of 0.12x Needle, approximately 8.5x faster, highlighting the ability of autotuning to optimize complex operations like matrix multiplications and attention mechanisms. Conv ResNet9 benefits drastically, achieving 0.10x Needle runtime, a 10x improvement, showcasing the impact of autotuning in optimizing convolution-heavy workloads. This combination unlocks the full potential of TVM for diverse workloads.\n",
    "\n",
    "Here are the highlights of the quantitative result:\n",
    "\n",
    "1. MLP benefits the most from TVM's optimizations, particularly autotuning, with a speedup of over 12x compared to the baseline\n",
    "2. Transformer, while more complex, sees notable improvements, especially with autotuning, achieving a speedup of 8.5x\n",
    "3. Conv ResNet9 demonstrates the importance of autotuning for convolution-heavy models, achieving a 10x speedup over the baseline\n",
    "\n",
    "#### GPU\n",
    "\n",
    "The results showcase the performance improvements on NVIDIA T4 GPU  achieved through TVM GPU optimizations on three models: MLP, Transformer, and Conv ResNet9. The key takeaways from the analysis are as follows:\n",
    "\n",
    "| Model          | Needle Runtime (scaled) | TVM Runtime (scaled) |\n",
    "|----------------|--------------------------|-----------------------|\n",
    "| MLP            | 1                        | 0.1361687547         |\n",
    "| Transformer    | 1                        | 0.04388941894        |\n",
    "| Conv ResNet9   | 1                        | 0.0576553462         |\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"./images/gpu_benchmark.png\" alt=\"CPU Benchmark Results\" width=\"70%\">\n",
    "</div>\n",
    "\n",
    "## Explanation\n",
    "The optimization pipeline applies GPU-specific schedules targeting common computational patterns, such as matrix multiplication (Matmul), generalized matrix-vector products (GEMV), and reduction operations. The results indicate the efficacy of the pipeline in optimizing specific workloads; for instance, the scaled runtime shows significant improvements in execution times for TVM. The varying relative execution times across models suggest that operations with higher computational intensity, such as those in Transformers and Conv ResNet9, benefit more from the pipelines optimizations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thtRRydD-p_2"
   },
   "source": [
    "# Conlcusion\n",
    "\n",
    "This project demonstrates the seamless integration of the Needle framework with TVM, unlocking advanced optimization capabilities to significantly enhance model performance. By translating Needle's computational graph into TVM's IRModule, we leverage graph-level and tensor program-level optimizations to achieve efficient execution across diverse hardware platforms.\n",
    "\n",
    "Our evaluation demonstrates the performance impact of integrating TVM with the Needle framework across three models: MLP, Transformer, and a convolutional ResNet9. Initially, without any optimizations, TVM underperforms compared to the baseline. However, with operator fusion enabled, the performance aligns closely with the baseline. The true potential of TVM is unlocked through autotuning, which delivers an impressive 812x speedup compared to the baseline. These results highlight the transformative power of TVMs advanced optimization capabilities, emphasizing the value of its integration into lightweight deep learning frameworks like Needle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SNu-EJ_7k4m"
   },
   "source": [
    "# Reference:\n",
    "\n",
    "[1] Apache TVM. TVM Documentation. Available at: [https://tvm.apache.org/docs/](https://tvm.apache.org/docs/)  \n",
    "[2] Machine Learning Compilation. Online course developed by Tianqi Chen. Available at: [https://mlc.ai](https://mlc.ai)  \n",
    "[3] PyTorch torch.fx. PyTorch Torch.fx Documentation. Available at: [https://pytorch.org/docs/stable/fx.html](https://pytorch.org/docs/stable/fx.html)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
